{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for testing chart data reconstruction from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from typing import Optional\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_output_root = \"data/scraped/camel/charts\"\n",
    "filepath_sample_image = os.path.join(filepath_output_root, \"camelcamelcamel-B07B428M7F.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utility functions\n",
    "\n",
    "def show(img):\n",
    "  # shows image\n",
    "\tw = img.shape[1]\n",
    "\th = img.shape[0]\n",
    "\ta = w/h\n",
    "\t# show image with 1200px width and proportional height\n",
    "\tplt.figure(figsize=(12,12/a))\n",
    "\tplt.imshow(img)\n",
    "\n",
    "def mask_image(img: np.ndarray,\n",
    "               color: tuple,\n",
    "               color_range: Optional[tuple] = None) -> np.ndarray:\n",
    "\t'''\n",
    "\t\tReturns a masked image where only the pixels of the specified color are kept.\n",
    "\t\tIf two colors are specified, the pixels between the two colors are kept.\n",
    "\t'''\n",
    "\timg_copy = img.copy()\n",
    "\tif color_range is None:\n",
    "\t\tcolor_range = color\n",
    "\timg_masked = cv.inRange(img_copy, np.array(color), np.array(color_range))\n",
    "\treturn img_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image from file as sample_image_original (BGR2RGB)\n",
    "sample_image_original = cv.imread(filepath_sample_image)\n",
    "sample_image_original = cv.cvtColor(sample_image_original, cv.COLOR_BGR2RGB)\n",
    "# print w, h, a\n",
    "w = sample_image_original.shape[1]\n",
    "h = sample_image_original.shape[0]\n",
    "a = w/h\n",
    "print(f\"w: {w}, h: {h}, a: {a}\")\n",
    "\n",
    "# print image shape (numpy)\n",
    "print(f\"sample_image_original.shape: {sample_image_original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(img: np.ndarray, filename: str, invert: bool = True) -> None:\n",
    "\t'''\n",
    "\t\tSaves image to file in the filepath_output_root directory.\n",
    "\t'''\n",
    "\tfilepath = os.path.join(filepath_output_root, filename)\n",
    "\tif invert:\n",
    "\t\timg_reverse = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "\t\tcv.imwrite(filepath, img_reverse)\n",
    "\telse:\n",
    "\t\tcv.imwrite(filepath, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(sample_image_original)\n",
    "save_image(sample_image_original, \"cv-demo-original.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_colors = get_all_unique_colors(sample_image_original)\n",
    "# print(unique_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment into two images - one image which only keeps the (#1D35CB powertoys color picker / #0033cc photoshop) color and one which keeps everything else\n",
    "# image_segmented_line should only contain one color\n",
    "# image_segmented_line = cv.inRange(sample_image_original, np.array([0, 51, 204]), np.array([0, 51, 204]))\n",
    "image_segmented_line = mask_image(sample_image_original, (0, 51, 204))\n",
    "\n",
    "# save to disk - same path as original image but with .png replaced with -segmented.png (in RGB)\n",
    "# filepath_sample_image_segmented = filepath_sample_image.replace(\".png\", \"-segmented.png\")\n",
    "# cv.imwrite(filepath_sample_image_segmented, image_segmented_line)\n",
    "show(image_segmented_line)\n",
    "save_image(image_segmented_line, \"cv-demo-segmented-plot.png\")\n",
    "\n",
    "# # decrease line thickness\n",
    "# kernel = np.ones((3,3),np.uint8)\n",
    "# image_segmented_line = cv.erode(image_segmented_line,kernel,iterations = 1)\n",
    "\n",
    "# display image (RGB)\n",
    "# plt.imshow(cv.cvtColor(image_segmented_line, cv.COLOR_BGR2RGB))\n",
    "# show(image_segmented_line)\n",
    "# image_segmented_line = cv.cvtColor(image_segmented_line, cv.COLOR_GRAY2RGB)\n",
    "# # display image (RGB)\n",
    "# # plt.imshow(cv.cvtColor(image_segmented, cv.COLOR_BGR2RGB))\n",
    "# show(image_segmented_line)\n",
    "\n",
    "# get unique values in resulting image\n",
    "# unique_values = np.unique(image_segmented_line)\n",
    "# print(f\"unique_values: {unique_values}\")\n",
    "\n",
    "# get counts of unique values in resulting image\n",
    "unique_values, counts = np.unique(image_segmented_line, return_counts=True)\n",
    "print(f\"unique_values: {unique_values} counts: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key algo for getting chart line coordinates\n",
    "def get_vertical_pixel_indices(img):\n",
    "\t'''\n",
    "\t\tReturns a list (length is same as img) where each element is a an index\n",
    "\t\tof the center of the first and last non-zero pixel in the column (vertical pixel line)\n",
    "\t\tIf no non-zero pixel if found in a column the element at that index equals -1.\n",
    "\n",
    "\t\tUseful for getting the averaged coordinates of the chart line.\n",
    "\t\tExample: element in list at index 3 has a value of 5 -> (3, 5) ; (x, y) ; (width_i, height_i) of the image\n",
    "\t\tThe coordinate system for images starts at the top left corner of the image.\n",
    "\t'''\n",
    "\t# make a copy of the image so we don't modify the original\n",
    "\timg_copy = img.copy()\n",
    "\t# mask the image to only keep the line color\n",
    "\timg_masked = cv.inRange(img_copy, np.array([0, 51, 204]), np.array([0, 51, 204]))\n",
    "\t# show(img_masked)\n",
    "\t# # convert image to black and white\n",
    "\t# # Set the threshold value\n",
    "\t# threshold_value = 127\n",
    "\t# # Set the maximum value\n",
    "\t# max_value = 255\n",
    "\t# # Convert the image to grayscale if it is not already\n",
    "\t# gray_img = img_masked\n",
    "\t# if len(img_copy.shape) > 2:\n",
    "\t# \tgray_img = cv.cvtColor(img_copy, cv.COLOR_RGB2GRAY)\n",
    "\t# # Threshold the image\n",
    "\t# ret, bw_img = cv.threshold(gray_img, threshold_value, max_value, cv.THRESH_BINARY)\n",
    "\t# # Invert the image // no longer needed - here for reference\n",
    "\t# bw_img = cv.bitwise_not(bw_img)\n",
    "\tvertical_pixel_indices = []\n",
    "\t# slice the image into vertical pixel segments\n",
    "\t# arr_img = np.array(bw_img)\n",
    "\t# arr_img = np.array(img_masked)\n",
    "\t# # transpose the array to make it easier to loop through each column (now row)\n",
    "\t# arr_img = arr_img.T\n",
    "\t# loop through each row\n",
    "\tfor i, row in enumerate(img_masked.T):\n",
    "\t\t# Find the indices of the non-zero elements\n",
    "\t\tnz_indices = np.nonzero(row)[0]\n",
    "\t\t# If there are no non-zero elements, add -1 to the list\n",
    "\t\tif len(nz_indices) == 0:\n",
    "\t\t\tvertical_pixel_indices.append(-1)\n",
    "\t\t\tcontinue\n",
    "\t\t# Find the first and last non-zero indices\n",
    "\t\tfirst_nz_index = nz_indices[0]\n",
    "\t\tlast_nz_index = nz_indices[-1]\n",
    "\t\t# Find the average of the first and last non-zero indices\n",
    "\t\tavg_nz_index = (first_nz_index + last_nz_index) / 2\n",
    "\t\t# Get the integer part of the average index\n",
    "\t\tavg_nz_index = int(avg_nz_index)\n",
    "\t\t# Add the average index to the list\n",
    "\t\tvertical_pixel_indices.append(avg_nz_index)\n",
    "\t# return the list\n",
    "\treturn vertical_pixel_indices\n",
    "\n",
    "filepath_img16x9bw = \"src/py/scraping/camel/16x9bw.png\"\n",
    "# img16x9bw = cv.cvtColor(cv.imread(filepath_img16x9bw), cv.COLOR_BGR2RGB)\n",
    "# show(img16x9bw)\n",
    "\n",
    "# demo on the real deal\n",
    "filepath_img16x9bw = filepath_sample_image\n",
    "img16x9bw =  cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "img16x9bw = cv.inRange(sample_image_original, np.array([0, 51, 204]), np.array([0, 51, 204]))\n",
    "# show(img16x9bw)\n",
    "\n",
    "# get the vertical pixel indices\n",
    "vertical_pixel_indices = get_vertical_pixel_indices(sample_image_original)\n",
    "\n",
    "# if the image has 2 dimensions, convert to 3 dimensions\n",
    "if len(img16x9bw.shape) == 2:\n",
    "\timg16x9bw = cv.cvtColor(img16x9bw, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "# paint the vertical pixel indices on the image with red\n",
    "# for i in range(len(vertical_pixel_indices)):\n",
    "# \tvertical_pixel_index = vertical_pixel_indices[i]\n",
    "# \tif vertical_pixel_index != -1:\n",
    "# \t\timg16x9bw[vertical_pixel_index, i] = [255, 0, 0]\n",
    "\n",
    "# connect the vertical pixel indices with a 1 pixel wide red line\n",
    "for i in range(len(vertical_pixel_indices) - 1):\n",
    "\tvertical_pixel_index = vertical_pixel_indices[i]\n",
    "\tnext_vertical_pixel_index = vertical_pixel_indices[i + 1]\n",
    "\tif vertical_pixel_index != -1 and next_vertical_pixel_index != -1:\n",
    "\t\tcv.line(img16x9bw, (i, vertical_pixel_index), (i + 1, next_vertical_pixel_index), (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "# show the image\n",
    "show(img16x9bw)\n",
    "\n",
    "# change to RGB from BGR\n",
    "# img16x9bw = cv.cvtColor(img16x9bw, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# save to disk\n",
    "save_image(img16x9bw, \"cv-demo-vertical-pixel-indices.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "We can now trace the line. We now need to:\n",
    "* find 0,0 pixels (axis origin)\n",
    "* find the axis labels (their values and their positions)\n",
    "* find the axis ticks (their values and their positions)\n",
    "* how to consistently mask the legend and text so it doesn't affect the line mask\n",
    "* calculate pixel to value ratio for each axis (and how accurate it is)\n",
    "* reconstruct the chart in library of choice (matplotlib, plotly, etc.)\n",
    "* compare the reconstructed chart to the original chart\n",
    "* save raw data to csv (timestamp, price) = (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the axis locations\n",
    "def get_axis_locations(img):\n",
    "\t'''\n",
    "\t\tFind the locations of the x and y axes in the image.\n",
    "\t'''\n",
    "\t# Make a copy of the image so we don't modify the original\n",
    "\timg_copy = img.copy()\n",
    "\t# Mask the image\n",
    "\timg_mask = cv.inRange(img_copy, np.array([51, 51, 51]), np.array([51, 51, 51]))\n",
    "\tshow(img_mask)\n",
    "\t# create an array with only zeros the size of image width and then another with only zeros the size of image height\n",
    "\tscanline_x = np.logical_not(np.zeros(img_mask.shape[1]))\n",
    "\tscanline_y = np.logical_not(np.zeros(img_mask.shape[0]))\n",
    "\thighest_match_count_x = 0\n",
    "\thighest_match_count_y = 0\n",
    "\thighest_match_count_x_indices = []\n",
    "\thighest_match_count_y_indices = []\n",
    "\t# loop through each row and use nand to find the number of matches\n",
    "\tfor i, row in enumerate(img_mask):\n",
    "\t\t# find the number of matches\n",
    "\t\tmatch_count = np.sum(np.logical_and(row, scanline_x))\n",
    "\t\t# if the match count is higher than the highest match count, set the highest match count to the match count\n",
    "\t\tif match_count > highest_match_count_x:\n",
    "\t\t\thighest_match_count_x = match_count\n",
    "\t\t\thighest_match_count_x_indices = [i]\n",
    "\t\t# if the match count is equal to the highest match count, append the index to the highest match count indices\n",
    "\t\telif match_count == highest_match_count_x:\n",
    "\t\t\thighest_match_count_x_indices.append(i)\n",
    "\t# loop through each column (image transposed to rows) and use nand to find the number of matches\n",
    "\tfor i, column in enumerate(img_mask.T):\n",
    "\t\t# find the number of matches\n",
    "\t\tmatch_count = np.sum(np.logical_and(column, scanline_y))\n",
    "\t\t# if the match count is higher than the highest match count, set the highest match count to the match count\n",
    "\t\tif match_count > highest_match_count_y:\n",
    "\t\t\thighest_match_count_y = match_count\n",
    "\t\t\thighest_match_count_y_indices = [i]\n",
    "\t\t# if the match count is equal to the highest match count, append the index to the highest match count indices\n",
    "\t\telif match_count == highest_match_count_y:\n",
    "\t\t\thighest_match_count_y_indices.append(i)\n",
    "\t# find the average of the highest match count indices\n",
    "\tavg_highest_match_count_x_index = int(np.average(highest_match_count_x_indices))\n",
    "\tavg_highest_match_count_y_index = int(np.average(highest_match_count_y_indices))\n",
    "\t# return the average highest match count indices\n",
    "\treturn avg_highest_match_count_x_index, avg_highest_match_count_y_index\n",
    "\n",
    "  \n",
    "# load image from file as sample_image_original (BGR2RGB)\n",
    "img = cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "axis_locations = get_axis_locations(img)\n",
    "\n",
    "# draw a line at the x axis location\n",
    "cv.line(img, (0, axis_locations[0]), (img.shape[1], axis_locations[0]), (0, 255, 0), 3)\n",
    "# draw a line at the y axis location\n",
    "cv.line(img, (axis_locations[1], 0), (axis_locations[1], img.shape[0]), (0, 255, 0), 3)\n",
    "# show the image\n",
    "show(img)\n",
    "# save to disk\n",
    "save_image(img, \"cv-demo-axis-locations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_indices_generic(img: np.ndarray, is_horizontal: bool, color: tuple, match_threshold: float = 0.2) -> list:\n",
    "\t'''\n",
    "\t\tFind the locations of the lines in the image.\n",
    "\t'''\n",
    "\t# mask the image\n",
    "\timg_mask = mask_image(img, color)\n",
    "\t# show(img_mask)\n",
    "\tscanline = None\n",
    "\t# generate scanline\n",
    "\tif is_horizontal:\n",
    "\t\tscanline = np.logical_not(np.zeros(img_mask.shape[1]))\n",
    "\telse:\n",
    "\t\tscanline = np.logical_not(np.zeros(img_mask.shape[0]))\n",
    "\tmatches_indices = []\n",
    "\t# loop through each row and use logical and to find the number of matches\n",
    "\timg_mask = img_mask if is_horizontal else img_mask.T\n",
    "\tfor i, row in enumerate(img_mask):\n",
    "\t\tmatch_count = np.sum(np.logical_and(row, scanline))\n",
    "\t\tmatch_ratio = match_count / img_mask.shape[1]\n",
    "\t\tif match_ratio > match_threshold:\n",
    "\t\t\tmatches_indices.append(i)\n",
    "\treturn matches_indices\n",
    "\n",
    "img = cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "# get the horizontal gridlines\n",
    "horizontal_gridlines = get_line_indices_generic(img, True, (221, 221, 221))\n",
    "# get the vertical gridlines\n",
    "vertical_gridlines = get_line_indices_generic(img, False, (221, 221, 221))\n",
    "# draw the horizontal gridlines\n",
    "for i in horizontal_gridlines:\n",
    "\tcv.line(img, (0, i), (img.shape[1], i), (255, 0, 255), 3)\n",
    "# draw the vertical gridlines\n",
    "for i in vertical_gridlines:\n",
    "\tcv.line(img, (i, 0), (i, img.shape[0]), (0, 255, 255), 3)\n",
    "# get price max and min indices\n",
    "price_max_index = get_line_indices_generic(img, True, (194, 68, 68), 0.2)[0]\n",
    "price_min_index = get_line_indices_generic(img, True, (119, 195, 107), 0.2)[0]\n",
    "cv.line(img, (0, price_max_index), (img.shape[1], price_max_index), (255, 127, 0), 3)\n",
    "cv.line(img, (0, price_min_index), (img.shape[1], price_min_index), (255, 127, 0), 3)\n",
    "# show the image\n",
    "show(img)\n",
    "# save to disk\n",
    "save_image(img, \"cv-demo-gridlines.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consecutive_elements(arr):\n",
    "\tconsecutive_lists = []\n",
    "\tcurrent_list = [arr[0]]\n",
    "\tfor i in range(1, len(arr)):\n",
    "\t\t\tif arr[i] == arr[i-1] + 1:\n",
    "\t\t\t\t\tcurrent_list.append(arr[i])\n",
    "\t\t\telse:\n",
    "\t\t\t\t\tconsecutive_lists.append(current_list)\n",
    "\t\t\t\t\tcurrent_list = [arr[i]]\n",
    "\tconsecutive_lists.append(current_list)\n",
    "\treturn consecutive_lists\n",
    "\n",
    "\n",
    "def merge_consecutive_elements(arr):\n",
    "\tmerged_list = []\n",
    "\tfor els in arr:\n",
    "\t\tmerged_list.append(int(np.average(els)))\n",
    "\treturn merged_list\n",
    "\n",
    "\n",
    "# arr = np.array([33, 34, 100, 101, 102, 105, 108])\n",
    "# consecutive_lists = get_consecutive_elements(arr)\n",
    "# print(consecutive_lists)\n",
    "# merged_list = merge_consecutive_elements(consecutive_lists)\n",
    "# print(merged_list)\n",
    "# a = 0\n",
    "\n",
    "# Getting major grid locations\n",
    "def get_major_grid_locations(img):\n",
    "\t'''\n",
    "\t\tFind the locations of the x and y grid locations in the image.\n",
    "\t'''\n",
    "\t# make a copy of the image so we don't modify the original\n",
    "\timg_copy = img.copy()\n",
    "\t# mask the image\n",
    "\timg_mask = cv.inRange(img_copy, np.array([221, 221, 221]), np.array([221, 221, 221]))\n",
    "\t# show(img_mask)\n",
    "\t# create an array with only zeros the size of image width and then another with only zeros the size of image height\n",
    "\tratio_to_match = 0.2 # ratio of the image width or height must be white to be considered a major grid line\n",
    "\tscanline_x = np.logical_not(np.zeros(img_mask.shape[1]))\n",
    "\tscanline_y = np.logical_not(np.zeros(img_mask.shape[0]))\n",
    "\tmatches_x_indices = []\n",
    "\tmatches_y_indices = []\n",
    "\t# loop through each row and use nand to find the number of matches\n",
    "\tfor i, row in enumerate(img_mask):\n",
    "\t\t# find the number of matches\n",
    "\t\t# match_count = np.sum(np.logical_and(np.logical_not(row), np.logical_not(scanline_x)))\n",
    "\t\tmatch_count = np.sum(np.logical_and(row, scanline_x))\n",
    "\t\tmatch_ratio = match_count / img_mask.shape[1]\n",
    "\t\tif match_ratio > ratio_to_match:\n",
    "\t\t\tmatches_x_indices.append(i)\n",
    "\t# loop through each column (image transposed to rows) and use nand to find the number of matches\n",
    "\tfor i, column in enumerate(img_mask.T):\n",
    "\t\t# find the number of matches\n",
    "\t\t# match_count = np.sum(np.logical_and(np.logical_not(column), np.logical_not(scanline_y)))\n",
    "\t\tmatch_count = np.sum(np.logical_and(column, scanline_y))\n",
    "\t\tmatch_ratio = match_count / img_mask.shape[0]\n",
    "\t\tif match_ratio > ratio_to_match:\n",
    "\t\t\tmatches_y_indices.append(i)\n",
    "\t# return the gridlines\n",
    "\treturn matches_x_indices, matches_y_indices\n",
    "\n",
    "def get_rightmost_minor_gridline(img):\n",
    "\t'''\n",
    "\t\tFind the location of the rightmost minor gridline in the image.\n",
    "\t\tAlso serves as the right side of the bounding box for the graph (line chart).\n",
    "\t'''\n",
    "\t# make a copy of the image so we don't modify the original\n",
    "\timg_copy = img.copy()\n",
    "\t# mask the image\n",
    "\timg_mask = cv.inRange(img_copy, np.array([245, 245, 245]), np.array([245, 245, 245]))\n",
    "\t# show(img_mask)\n",
    "\t# create an array with only zeros the size of image height\n",
    "\tscanline_y = np.logical_not(np.zeros(img_mask.shape[0]))\n",
    "\tmatches_y_indices = []\n",
    "\taccepable_match_ratio = 0.2 # ratio of the image height must be white to be considered a major grid line\n",
    "\tfor i, column in enumerate(img_mask.T):\n",
    "\t\t# find the number of matches\n",
    "\t\tmatch_count = np.sum(np.logical_and(column, scanline_y))\n",
    "\t\tmatch_ratio = match_count / img_mask.shape[0]\n",
    "\t\tif match_ratio > accepable_match_ratio:\n",
    "\t\t\tmatches_y_indices.append(i)\n",
    "\t# return the highest index\n",
    "\treturn max(matches_y_indices)\n",
    "\n",
    "  \n",
    "# load image from file as sample_image_original (BGR2RGB)\n",
    "img = cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "major_grid_locations_x, major_grid_locations_y = get_major_grid_locations(img)\n",
    "\n",
    "rightmost_minor_gridline = get_rightmost_minor_gridline(img)\n",
    "\n",
    "major_grid_locations_x = merge_consecutive_elements(get_consecutive_elements(major_grid_locations_x))\n",
    "major_grid_locations_y = merge_consecutive_elements(get_consecutive_elements(major_grid_locations_y))\n",
    "\n",
    "# draw a horizonal red line at the x axis location for each major grid location\n",
    "min_x = min(major_grid_locations_x) # top of the graph (line chart) bounding box\n",
    "for x in major_grid_locations_x:\n",
    "\tif x == min_x:\n",
    "\t\tcv.line(img, (0, x), (img.shape[1], x), (0, 255, 0), 3)\n",
    "\t# else:\n",
    "\t# \tcv.line(img, (0, x), (img.shape[1], x), (255, 0, 0), 3)\n",
    "# draw a vertical red line at the y axis location for each major grid location\n",
    "# for y in major_grid_locations_y:\n",
    "# \tcv.line(img, (y, 0), (y, img.shape[0]), (255, 0, 0), 3)\n",
    "# draw a vertical cyan line at the rightmost minor gridline location\n",
    "cv.line(img, (rightmost_minor_gridline, 0), (rightmost_minor_gridline, img.shape[0]), (0, 255, 0), 3)\n",
    "# show the image\n",
    "# draw axis lines\n",
    "cv.line(img, (0, axis_locations[0]), (img.shape[1], axis_locations[0]), (0, 255, 0), 3)\n",
    "cv.line(img, (axis_locations[1], 0), (axis_locations[1], img.shape[0]), (0, 255, 0), 3)\n",
    "# draw price max and min lines\n",
    "cv.line(img, (0, price_max_index), (img.shape[1], price_max_index), (255, 0, 255), 3)\n",
    "cv.line(img, (0, price_min_index), (img.shape[1], price_min_index), (255, 0, 255), 3)\n",
    "show(img)\n",
    "save_image(img, \"cv-demo-bounding-box.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = set(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'nov', 'dec'])\n",
    "\n",
    "def clean_str(s):\n",
    "\t'''\n",
    "\t\tRemove all non-alphanumeric characters from a string.\n",
    "\t'''\n",
    "\ts_clean = s.replace(' ', '')\n",
    "\ts_clean = s_clean.strip()\n",
    "\ts_clean = s_clean.lower()\n",
    "\ts_clean = re.sub('[^0-9a-zA-Z]+', '', s_clean)\n",
    "\treturn s_clean\n",
    "\n",
    "def tesseract_data_object_to_list_of_objects(data):\n",
    "\t'''\n",
    "\t\tConvert the tesseract data object to a list of objects.\n",
    "\t'''\n",
    "\tdata_list = []\n",
    "\tfor i in range(len(data[\"text\"])):\n",
    "\t\tel = {}\n",
    "\t\tfor k in data:\n",
    "\t\t\tel[k] = data[k][i]\n",
    "\t\tdata_list.append(el)\n",
    "\treturn data_list\n",
    "\n",
    "# Read all of the text from the image\n",
    "\n",
    "def get_y_axis_label_candidates(candidates):\n",
    "\t'''\n",
    "\t\tFind the y axis label candidates.\n",
    "\t'''\n",
    "\t# find the y axis label candidates\n",
    "\ty_axis_label_candidates = []\n",
    "\tfor candidate in candidates:\n",
    "\t\t# get the text from the candidate\n",
    "\t\ttext = candidate['text']\n",
    "\t\tif \"$\" in text and \".\" not in text:\n",
    "\t\t\ty_axis_label_candidates.append(candidate)\n",
    "\treturn y_axis_label_candidates\n",
    "\n",
    "def get_x_axis_month_label_candidates(candidates):\n",
    "\t'''\n",
    "\t\tFind the x axis month label candidates.\n",
    "\t'''\n",
    "\t# find the x axis month label candidates\n",
    "\tx_axis_month_label_candidates = []\n",
    "\tfor candidate in candidates:\n",
    "\t\t# get the text from the candidate\n",
    "\t\ttext = candidate['text']\n",
    "\t\tif clean_str(text) in months:\n",
    "\t\t\tx_axis_month_label_candidates.append(candidate)\n",
    "\treturn x_axis_month_label_candidates\n",
    "\n",
    "def get_month_labels_y_location(candidates):\n",
    "\t'''\n",
    "\t\tFind the y axis location of the month labels. Used for determining x axis year label candidates.\n",
    "\t'''\n",
    "\ty_locations = {}\n",
    "\tfor candidate in candidates:\n",
    "\t\ty = str(candidate['top'])\n",
    "\t\tif y not in y_locations:\n",
    "\t\t\ty_locations[y] = []\n",
    "\t\ty_locations[y].append(candidate)\n",
    "\t# y_location is the key with the most values\n",
    "\ty_location = int(max(y_locations, key=lambda k: len(y_locations[k])))\n",
    "\t# return the y location of the month labels\n",
    "\treturn y_location\n",
    "\n",
    "def get_x_axis_year_label_candidates(candidates, y_location):\n",
    "\t'''\n",
    "\t\tFind the x axis year label candidates.\n",
    "\t'''\n",
    "\t# find the x axis year label candidates\n",
    "\tx_axis_year_label_candidates = []\n",
    "\tfor candidate in candidates:\n",
    "\t\t# get the text from the candidate\n",
    "\t\ttext = candidate['text']\n",
    "\t\t# get the y location from the candidate\n",
    "\t\ty = candidate['top']\n",
    "\t\t# if the text is a digit and the y location is near (3 pixels + or -) the y location of the month labels\n",
    "\t\tif text.isdigit() and abs(y - y_location) <= 3:\n",
    "\t\t\tx_axis_year_label_candidates.append(candidate)\n",
    "\treturn x_axis_year_label_candidates\n",
    "\n",
    "def get_text_data(img):\n",
    "\t'''\n",
    "\t\tGet the text data from the image.\n",
    "\t'''\n",
    "\t# show(img)\n",
    "\tgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\t# show(gray)\n",
    "\tthresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)[1]\n",
    "\t# show(thresh)\n",
    "\tkernel = cv.getStructuringElement(cv.MORPH_RECT, (3,3))\n",
    "\t# show(kernel)\n",
    "\tdilate = cv.dilate(thresh, kernel, iterations=1)\n",
    "\t# show(dilate)\n",
    "\t# boxes = pytesseract.image_to_data(dilate, output_type=Output.DICT)\n",
    "\t# boxes = pytesseract.image_to_data(dilate, output_type=Output.DICT, config='--psm 6')\n",
    "\t# boxes = pytesseract.image_to_data(dilate, output_type=Output.DICT, config='--psm 6 -c tessedit_char_whitelist=0123456789')\n",
    "\t# boxes = pytesseract.image_to_data(dilate, output_type=Output.DICT, config='--psm 6 --oem 3')\n",
    "\t# boxes = pytesseract.image_to_data(img, output_type=Output.DICT, config='--psm 6 --oem 3') \n",
    "\tboxes = pytesseract.image_to_data(gray, output_type=Output.DICT, config='--psm 6 --oem 3') # currently the best\n",
    "\treturn boxes\n",
    "\n",
    "img = cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "boxes = get_text_data(img)\n",
    "conf = 80 #90\n",
    "for i in range(len(boxes['text'])):\n",
    "\tif int(boxes['conf'][i]) > conf:\n",
    "\t\t(x, y, w, h) = (boxes['left'][i], boxes['top'][i], boxes['width'][i], boxes['height'][i])\n",
    "\t\tcv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "# show(img)\n",
    "\n",
    "# convert the tesseract data object to a list of objects\n",
    "boxes = tesseract_data_object_to_list_of_objects(boxes)\n",
    "# filter out the non-text boxes\n",
    "boxes = [b for b in boxes if b['text'].strip() != '']\n",
    "# filter out the boxes with low confidence\n",
    "boxes = [b for b in boxes if int(b['conf']) > conf]\n",
    "\n",
    "y_label_candidates = get_y_axis_label_candidates(boxes)\n",
    "# print candidates text\n",
    "print(\"y axis (price) label candidates:\")\n",
    "for candidate in y_label_candidates:\n",
    "\tprint(f\"'{candidate['text']}' at ({candidate['left']}, {candidate['top']})\")\n",
    "\n",
    "x_month_candidates = get_x_axis_month_label_candidates(boxes)\n",
    "x_month_y_location = get_month_labels_y_location(x_month_candidates)\n",
    "\n",
    "x_year_candidates = get_x_axis_year_label_candidates(boxes, x_month_y_location)\n",
    "# print candidates text\n",
    "print(\"x axis (year) label candidates:\")\n",
    "for candidate in x_year_candidates:\n",
    "\tprint(f\"'{candidate['text']}' at ({candidate['left']}, {candidate['top']})\")\n",
    "\n",
    "# print the text from the image and the confidence of each result\n",
    "# for i in range(len(boxes['text'])):\n",
    "# \tif int(boxes['conf'][i]) > conf:\n",
    "# \t\ttext = clean_str(boxes['text'][i])\n",
    "# \t\tif (\"$\" in text and \".\" not in text) or (text in months):\n",
    "# \t\t\tprint(f\"'{text}': {boxes['conf'][i]} % at ({boxes['left'][i]}, {boxes['top'][i]}) ; original string: '{boxes['text'][i]}'\")\n",
    "\n",
    "# paint the boinding boxes of x and y axis labels on the image in magenta\n",
    "for candidate in y_label_candidates:\n",
    "\t(x, y, w, h) = (candidate['left'], candidate['top'], candidate['width'], candidate['height'])\n",
    "\tcv.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
    "# for candidate in x_month_candidates:\n",
    "# \t(x, y, w, h) = (candidate['left'], candidate['top'], candidate['width'], candidate['height'])\n",
    "# \tcv.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "for candidate in x_year_candidates:\n",
    "\t(x, y, w, h) = (candidate['left'], candidate['top'], candidate['width'], candidate['height'])\n",
    "\tcv.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
    "show(img)\n",
    "save_image(img, \"cv-demo-text-data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to bring it all together - first we have to match the x and y axis labels with the major gridlines\n",
    "img = cv.cvtColor(cv.imread(filepath_sample_image), cv.COLOR_BGR2RGB)\n",
    "x_axis_location, y_axis_location = get_axis_locations(img)\n",
    "rightmost_minor_gridline = get_rightmost_minor_gridline(img)\n",
    "print(f\"x axis location: {x_axis_location}\")\n",
    "print(f\"y axis location: {y_axis_location}\")\n",
    "print(f\"rightmost minor gridline location (right side of the bounding box): {rightmost_minor_gridline}\")\n",
    "# get gridlines\n",
    "grid_y_locations, grid_x_locations = get_major_grid_locations(img)\n",
    "grid_x_locations = merge_consecutive_elements(get_consecutive_elements(grid_x_locations))\n",
    "grid_y_locations = merge_consecutive_elements(get_consecutive_elements(grid_y_locations))\n",
    "# append the x axis to the gridlines as well\n",
    "grid_y_locations.append(x_axis_location)\n",
    "print(f\"grid x locations: {grid_x_locations}\")\n",
    "print(f\"grid y locations: {grid_y_locations}\")\n",
    "# get text from image\n",
    "text_data = get_text_data(img)\n",
    "text_data = tesseract_data_object_to_list_of_objects(text_data)\n",
    "# get y axis labels\n",
    "y_axis_label_candidates = get_y_axis_label_candidates(text_data)\n",
    "y_axis_labels = [candidate['text'] for candidate in y_axis_label_candidates]\n",
    "print(f\"y axis labels: {y_axis_labels}\")\n",
    "# get x axis labels\n",
    "x_month_candidates = get_x_axis_month_label_candidates(boxes)\n",
    "x_month_y_location = get_month_labels_y_location(x_month_candidates)\n",
    "x_axis_candidates = get_x_axis_year_label_candidates(boxes, x_month_y_location)\n",
    "x_axis_labels = [candidate['text'] for candidate in x_axis_candidates]\n",
    "print(f\"x axis labels: {x_axis_labels}\")\n",
    "\n",
    "def match_x_axis_label_candidates_with_gridlines(x_axis_label_candidates, grid_x_locations):\n",
    "\t'''\n",
    "\t\tTries matching the x axis label candidates center with the closest gridline.\n",
    "\t'''\n",
    "\tmatches = []\n",
    "\tbiggest_distance = 5 # the horizontal distance between the center of the label and the gridline\n",
    "\tfor candidate in x_axis_label_candidates:\n",
    "\t\tcenter = candidate['left'] + (candidate['width'] / 2)\n",
    "\t\tclosest_gridline = min(grid_x_locations, key=lambda x:abs(x-center))\n",
    "\t\tif abs(center - closest_gridline) < biggest_distance:\n",
    "\t\t\tmatches.append((candidate, closest_gridline))\n",
    "\treturn matches\n",
    "\n",
    "def match_y_axis_label_candidates_with_gridlines(y_axis_label_candidates, grid_y_locations):\n",
    "\t'''\n",
    "\t\tTries matching the y axis label candidates center with the closest gridline.\n",
    "\t'''\n",
    "\tmatches = []\n",
    "\tbiggest_distance = 5 # the vertical distance between the center of the label and the gridline\n",
    "\tfor candidate in y_axis_label_candidates:\n",
    "\t\tcenter = candidate['top'] + (candidate['height'] / 2)\n",
    "\t\tclosest_gridline = min(grid_y_locations, key=lambda y:abs(y-center))\n",
    "\t\tif abs(center - closest_gridline) < biggest_distance:\n",
    "\t\t\tmatches.append((candidate, closest_gridline))\n",
    "\treturn matches\n",
    "\t\n",
    "\n",
    "grid_x_matches = match_x_axis_label_candidates_with_gridlines(x_axis_candidates, grid_x_locations)\n",
    "# print matches (label, candidate center, and gridline)\n",
    "print(\"x axis label matches to gridline positions:\")\n",
    "for match in grid_x_matches:\n",
    "\tprint(f\"{match[0]['text']}: {match[0]['left'] + match[0]['width'] / 2} -> {match[1]}\")\n",
    "\n",
    "grid_y_matches = match_y_axis_label_candidates_with_gridlines(y_axis_label_candidates, grid_y_locations)\n",
    "# print matches (label, candidate center, and gridline)\n",
    "print(\"y axis label matches to gridline positions:\")\n",
    "for match in grid_y_matches:\n",
    "\tprint(f\"{match[0]['text']}: {match[0]['top'] + match[0]['height'] / 2} -> {match[1]}\")\n",
    "\n",
    "# getting the extreme values for the most accurate calculations\n",
    "x_pair_smallest = min(grid_x_matches, key=lambda x: x[1])\n",
    "x_pair_largest = max(grid_x_matches, key=lambda x: x[1])\n",
    "y_pair_smallest = min(grid_y_matches, key=lambda y: y[1])\n",
    "y_pair_largest = max(grid_y_matches, key=lambda y: y[1])\n",
    "# print the extreme values (table text, gridline)\n",
    "print(f\"smallest x value: {x_pair_smallest[0]['text']} @ {x_pair_smallest[1]}\")\n",
    "print(f\"largest x value: {x_pair_largest[0]['text']} @ {x_pair_largest[1]}\")\n",
    "# print(f\"smallest y value: {y_pair_smallest[0]['text']} @ {y_pair_smallest[1]}\")\n",
    "# print(f\"largest y value: {y_pair_largest[0]['text']} @ {y_pair_largest[1]}\")\n",
    "print(f\"smallest y value: {y_pair_largest[0]['text']} @ {y_pair_largest[1]}\")\n",
    "print(f\"largest y value: {y_pair_smallest[0]['text']} @ {y_pair_smallest[1]}\")\n",
    "\n",
    "# calculate the x and y axis pixel to value ratio (resolution)s\n",
    "x_smallest_timestamp = datetime(year=int(x_pair_smallest[0]['text']), month=1, day=1)\n",
    "x_largest_timestamp = datetime(year=int(x_pair_largest[0]['text']), month=1, day=1)\n",
    "# print the timestamps as human readable\n",
    "print(f\"smallest x timestamp: {x_smallest_timestamp}\")\n",
    "print(f\"largest x timestamp: {x_largest_timestamp}\")\n",
    "# calculate the y axis resolution\n",
    "y_smallest_value = float(clean_str(y_pair_smallest[0]['text']))\n",
    "y_largest_value = float(clean_str(y_pair_largest[0]['text']))\n",
    "# print(f\"smallest y value: {y_smallest_value} $\")\n",
    "# print(f\"largest y value: {y_largest_value} $\")\n",
    "print(f\"smallest y value: {y_largest_value} $\")\n",
    "print(f\"largest y value: {y_smallest_value} $\")\n",
    "\n",
    "# calculate different in x and y axis\n",
    "x_axis_difference_value = (x_largest_timestamp - x_smallest_timestamp).total_seconds()\n",
    "y_axis_difference_value = abs(y_largest_value - y_smallest_value)\n",
    "# calculate the difference in pixels between the extreme values\n",
    "x_axis_difference_pixels = abs(x_pair_largest[1] - x_pair_smallest[1])\n",
    "y_axis_difference_pixels = abs(y_pair_largest[1] - y_pair_smallest[1])\n",
    "print(f\"x axis difference: {x_axis_difference_value} seconds per {x_axis_difference_pixels} pixels\")\n",
    "print(f\"y axis difference: {y_axis_difference_value} $ per {y_axis_difference_pixels} pixels\")\n",
    "# print how much is 1 pixel in x and y axis\n",
    "x_seconds_per_pixel = x_axis_difference_value / x_axis_difference_pixels\n",
    "y_dollars_per_pixel = y_axis_difference_value / y_axis_difference_pixels\n",
    "print(f\"1 pixel on x axis is {x_seconds_per_pixel} seconds ({x_seconds_per_pixel / 86400} days)\")\n",
    "print(f\"1 pixel on y axis is {y_dollars_per_pixel} $\")\n",
    "\n",
    "# draw a horizontal line at the y axis label location\n",
    "cv.line(img, (0, int(x_axis_location)), (img.shape[1], int(x_axis_location)), (255, 0, 0), 3)\n",
    "# draw a vertical line at the x axis label location\n",
    "cv.line(img, (int(y_axis_location), 0), (int(y_axis_location), img.shape[0]), (255, 0, 0), 3)\n",
    "# draw a vertical cyan line at the rightmost_minor_gridline\n",
    "cv.line(img, (int(rightmost_minor_gridline), 0), (int(rightmost_minor_gridline), img.shape[0]), (0, 255, 255), 3)\n",
    "# draw gridlines\n",
    "for x in grid_x_locations:\n",
    "\tcv.line(img, (int(x), 0), (int(x), img.shape[0]), (0, 255, 0), 3)\n",
    "for y in grid_y_locations:\n",
    "\tcv.line(img, (0, int(y)), (img.shape[1], int(y)), (0, 255, 0), 3)\n",
    "# in magenta draw the x axis label candidates\n",
    "for candidate in x_axis_candidates:\n",
    "\tcv.rectangle(img, (candidate['left'], candidate['top']), (candidate['left'] + candidate['width'], candidate['top'] + candidate['height']), (255, 0, 255), 3)\n",
    "# in magenta draw the y axis label candidates\n",
    "for candidate in y_axis_label_candidates:\n",
    "\tcv.rectangle(img, (candidate['left'], candidate['top']), (candidate['left'] + candidate['width'], candidate['top'] + candidate['height']), (255, 0, 255), 3)\n",
    "show(img)\n",
    "save_image(img, \"cv-demo-final-overlay.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the timestamp of a given x axis pixel (coordinate system starts from top left)\n",
    "def calculate_timestamp_from_x_axis_pixel(gridline_pair, pixel_x, x_seconds_per_pixel):\n",
    "\t'''\n",
    "\t\tReturns the timestamp of a given x axis pixel in relation to the selected gridline pair axis using x_seconds_per_pixel.\n",
    "\t'''\n",
    "\tgridline = gridline_pair[1]\n",
    "\tgridline_timestamp = datetime(year=int(gridline_pair[0]['text']), month=1, day=1)\n",
    "\tpixels_diff = pixel_x - gridline\n",
    "\tseconds_from_gridline = pixels_diff * x_seconds_per_pixel\n",
    "\ttd = timedelta(seconds=seconds_from_gridline)\n",
    "\ttimestamp_at_pixel_x = gridline_timestamp + td\n",
    "\treturn timestamp_at_pixel_x\n",
    "\n",
    "# function to calculate the value of a given y axis pixel (coordinate system starts from top left)\n",
    "def calculate_value_from_y_axis_pixel(gridline_pair, pixel_y, y_dollars_per_pixel):\n",
    "\t'''\n",
    "\t\tReturns the value of a given y axis pixel in relation to the selected gridline pair axis using y_dollars_per_pixel.\n",
    "\t'''\n",
    "\tgridline = gridline_pair[1]\n",
    "\tgridline_value = float(clean_str(gridline_pair[0]['text']))\n",
    "\t# pixels_diff = pixel_y - gridline\n",
    "\tpixels_diff = gridline - pixel_y # invert the y axis - images start from top left\n",
    "\tdollars_from_gridline = pixels_diff * y_dollars_per_pixel\n",
    "\tsum_total = gridline_value + dollars_from_gridline\n",
    "\treturn sum_total\n",
    "\n",
    "time_of_y_axis = calculate_timestamp_from_x_axis_pixel(x_pair_smallest, y_axis_location, x_seconds_per_pixel)\n",
    "value_of_x_axis = calculate_value_from_y_axis_pixel(y_pair_smallest, x_axis_location, y_dollars_per_pixel)\n",
    "print(f\"pixel of x axis: {y_axis_location}\")\n",
    "print(f\"timestamp of x axis: {time_of_y_axis}\")\n",
    "print(f\"value of y axis: {value_of_x_axis} $\")\n",
    "\n",
    "# show(img)\n",
    "\n",
    "def mask_image_bounding_box(img, left, top, right, bottom):\n",
    "\t'''\n",
    "\t\tMasks the image with a bounding box.\n",
    "\t'''\n",
    "\timg_copy = img.copy()\n",
    "\tmask = np.zeros(img_copy.shape[:2], dtype=np.uint8)\n",
    "\tmask[top:bottom, left:right] = 255\n",
    "\tmasked_img = cv.bitwise_and(img_copy, img_copy, mask=mask)\n",
    "\t# show(masked_img)\n",
    "\treturn masked_img\n",
    "\n",
    "# x_axis_location, y_axis_location = get_axis_locations(img)\n",
    "# rightmost_minor_gridline = get_rightmost_minor_gridline(img)\n",
    "masked_img = mask_image_bounding_box(img, y_axis_location, y_pair_smallest[1], rightmost_minor_gridline, x_axis_location)\n",
    "\n",
    "# get vertical pixes indices from the image\n",
    "vertical_pixel_indices = get_vertical_pixel_indices(masked_img)\n",
    "# calculate x and y values for each pixel\n",
    "extracted_data = [] # TODO: save this data to a file - this is our FINAL result\n",
    "for y, x in enumerate(vertical_pixel_indices):\n",
    "\tif x == -1:\n",
    "\t\t# extracted_data.append((-1, -1))\n",
    "\t\tcontinue\t\n",
    "\tval_at_pixel_y = calculate_value_from_y_axis_pixel(y_pair_smallest, x, y_dollars_per_pixel)\n",
    "\tval_at_pixel_x = calculate_timestamp_from_x_axis_pixel(x_pair_smallest, y, x_seconds_per_pixel)\n",
    "\textracted_data.append((val_at_pixel_x, val_at_pixel_y))\n",
    "\n",
    "\n",
    "# simulate deleting 300 datapoints at index 500\n",
    "# del extracted_data[500:800]\n",
    "\n",
    "xs = [x[0] for x in extracted_data]\n",
    "ys = [x[1] for x in extracted_data]\n",
    "# for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "# \tprint(f\"{i + 1}. ({x} , {y})\")\n",
    "plt.plot(xs, ys)\n",
    "# add gridlines\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Reverse engineered chart')\n",
    "# plt.gcf().set_size_inches(12, 9)\n",
    "# set size pixels 3200x2400\n",
    "plt.gcf().set_size_inches(32, 24)\n",
    "# save to disk in high resolution\n",
    "plt_path = os.path.join(filepath_output_root, \"cv-demo-reverse-engineered-chart.png\")\n",
    "# plt.savefig(plt_path, dpi=300, bbox_inches='tight')\n",
    "# 3200x2400\n",
    "plt.savefig(plt_path, dpi=100, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
