{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invenstigating the Keepa API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import keepa\n",
    "from keepa.interface import keepa_minutes_to_time, parse_csv\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\tConstants and global variables\n",
    "'''\n",
    "\n",
    "# Load environment variables\n",
    "\n",
    "# API key\n",
    "API_KEY = os.environ.get('KEEPA_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = keepa.Keepa(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = api.query('B07B428M7F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = products[0]\n",
    "a = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepa.plot_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keepa_minutes_to_time\n",
    "last_update = keepa_minutes_to_time(product['lastUpdate'])\n",
    "print(last_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_csv = parse_csv(product['csv'])\n",
    "# print(parsed_csv.keys())\n",
    "keys = list(parsed_csv.keys())\n",
    "# # print in threes\n",
    "# for i in range(0, len(keys), 3):\n",
    "# \t\tprint(keys[i], keys[i + 1], keys[i + 2])\n",
    "\n",
    "key_objects = []\n",
    "for i in range(0, len(keys), 3):\n",
    "\t\tkey_objects.append(\n",
    "\t\t\t{\n",
    "\t\t\t\t'time': keys[i],\n",
    "\t\t\t\t'price': keys[i + 1],\n",
    "\t\t\t\t'df': keys[i + 2]\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "print(json.dumps(key_objects, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_date(date: datetime) -> datetime:\n",
    "\t'''\n",
    "\t\tReturns a copy of the datetime object, only keeping the year, month and day.\n",
    "\t'''\n",
    "\tdt = datetime.replace(date, hour=0, minute=0, second=0, microsecond=0)\n",
    "\treturn dt\n",
    "\n",
    "def discretize(arr_values: np.array, arr_dates: np.array) -> Tuple[np.array, np.array]:\n",
    "\t'''\n",
    "\t\tConverts all dates in a time series to only keep the year, month and day,\n",
    "\t\tchoosing the most recent consecutive date and discarding all others.\n",
    "\t'''\n",
    "\tif len(arr_values) != len(arr_dates):\n",
    "\t\traise ValueError('Length of arr_values and arr_dates must be equal.')\n",
    "\tarr_dates_discrete = []\n",
    "\tarr_values_discrete = []\n",
    "\tfor i in range(len(arr_values)):\n",
    "\t\tif i == len(arr_values) - 1:\n",
    "\t\t\tarr_dates_discrete.append(get_clean_date(arr_dates[i]))\n",
    "\t\t\tarr_values_discrete.append(arr_values[i])\n",
    "\t\t\tbreak\n",
    "\t\tdate = get_clean_date(arr_dates[i])\n",
    "\t\tvalue = arr_values[i]\n",
    "\t\tdate_next = get_clean_date(arr_dates[i + 1])\n",
    "\t\tif date != date_next:\n",
    "\t\t\tarr_dates_discrete.append(date)\n",
    "\t\t\tarr_values_discrete.append(value)\n",
    "\treturn np.array(arr_values_discrete), np.array(arr_dates_discrete)\n",
    "\n",
    "def fill_missing_dates(arr_values: np.array, arr_dates:np.array) -> Tuple[np.array, np.array]:\n",
    "\t'''\n",
    "\t\tFills the missing dates in a time series with NaN values.\n",
    "\t\tAssumes that the dates are sorted in ascending order, discrete and without duplicates.\n",
    "\t\t(running discretize() first is recommended)\n",
    "\t\tThis is useful for preparation for imputation methods.\n",
    "\t'''\n",
    "\tif len(arr_values) != len(arr_dates):\n",
    "\t\traise ValueError('Length of arr_values and arr_dates must be equal.')\n",
    "\tarr_dates_filled = []\n",
    "\tarr_values_filled = []\n",
    "\tfirst_date = arr_dates[0]\n",
    "\tmissing_dates_count = 0\n",
    "\tfor i in range(len(arr_values)):\n",
    "\t\tif i == len(arr_values) - 1:\n",
    "\t\t\tarr_dates_filled.append(arr_dates[i])\n",
    "\t\t\tarr_values_filled.append(arr_values[i])\n",
    "\t\t\tbreak\n",
    "\t\tdate = arr_dates[i]\n",
    "\t\tvalue = arr_values[i]\n",
    "\t\tdate_next = arr_dates[i + 1]\n",
    "\t\tif date == date_next:\n",
    "\t\t\tcontinue\n",
    "\t\tarr_dates_filled.append(date)\n",
    "\t\tarr_values_filled.append(value)\n",
    "\t\twhile date != date_next:\n",
    "\t\t\tmissing_dates_count += 1\n",
    "\t\t\tdate = date + timedelta(days=1)\n",
    "\t\t\tif date == date_next:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tarr_dates_filled.append(date)\n",
    "\t\t\tarr_values_filled.append(np.nan)\n",
    "\t\t\t\n",
    "\t\t\t# arr_values_filled.append(-1)\n",
    "\tmetadata = {\n",
    "\t\t'first_date': first_date,\n",
    "\t\t'last_date': arr_dates[-1],\n",
    "\t\t'missing_dates_count': len(arr_dates_filled) - len(arr_dates),\n",
    "\t\t'missing_dates_percentage': (len(arr_dates_filled) - len(arr_dates)) / len(arr_dates_filled) * 100\n",
    "\t}\n",
    "\treturn np.array(arr_values_filled), np.array(arr_dates_filled), metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for key in key_objects:\n",
    "\t# impute missing values by taking the last known value\n",
    "\t# parsed_csv[key[\"price\"]] = parsed_csv[key[\"price\"]].replace(-1, np.nan).fillna(method='ffill')\n",
    "\t# interp_func = interp1d(parsed_csv[key[\"time\"]], parsed_csv[key[\"price\"]], kind='linear', fill_value='extrapolate')\n",
    "\t# parse_csv[key[\"price\"]] = interp_func(parsed_csv[key[\"time\"]])\n",
    "\t\n",
    "\tprice_discrete, date_discrete = discretize(parsed_csv[key[\"price\"]], parsed_csv[key[\"time\"]])\n",
    "\tprice_filled, date_filled, metadata = fill_missing_dates(price_discrete, date_discrete)\n",
    "\t# create a df from the filled values and dates, where the dates are the index\n",
    "\tdf = pd.DataFrame({\"values\": price_filled}, index=date_filled)\n",
    "\t# print(df.head(20))\n",
    "\tdf = df.interpolate(method='linear', limit_direction='both')\n",
    "\t\n",
    "\n",
    "\tinterpolated_dates = df.index\n",
    "\tinterpolated_values = df[\"values\"]\n",
    "\tprint(f\"Key {key['price']} has {metadata['missing_dates_count']} missing dates ({metadata['missing_dates_percentage']}%)\")\n",
    "\tfig.add_trace(go.Scatter(x=interpolated_dates, y=interpolated_values, name=key[\"price\"]))#, mode='markers'))\n",
    "fig.update_layout(title='Price vs Time',\n",
    "\t\t\t\t\t\t\t\t\txaxis_title='Time',\n",
    "\t\t\t\t\t\t\t\t\tyaxis_title='Price',\n",
    "\t\t\t\t\t\t\t\t\tshowlegend=True\n",
    ")\n",
    "# add \n",
    "# fig.update_layout(width=1600, height=1200)\n",
    "# hide all but AMAZON, NEW, USED legend\n",
    "for i in range(3, len(fig.data)):\n",
    "\tfig.data[i].visible = 'legendonly'\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly graph AMAZON on x and AMAZON_time on y\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=parsed_csv['AMAZON_time'], y=parsed_csv['AMAZON'], name='AMAZON'))\n",
    "# add legend\n",
    "fig.update_layout(\n",
    "\tlegend=dict(\n",
    "\t\tyanchor=\"top\",\n",
    "\t\ty=0.99,\n",
    "\t\txanchor=\"left\",\n",
    "\t\tx=0.01\n",
    "\t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty print the product\n",
    "print(json.dumps(product, indent=2, default=str))#, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product search\n",
    "\n",
    "product_params = {\n",
    "\t# \"title\":\"ryzen 7 2700x\",\n",
    "  # \"categories_include\": [\n",
    "  #     229189, # \"CPU Processors\"\n",
    "  #     # 8588809011,\n",
    "  #     # 13900851\n",
    "\t# ],\n",
    "\t\"title\": \"amd ryzen 7 2700x\"\n",
    "\t# \"title\": \"AD4U266638G19-S\"\n",
    "\t# \"title\": \"intel core i7 10700k\"\n",
    "}\n",
    "products = api.product_finder(product_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len: {len(products)}\")\n",
    "print(json.dumps(products, indent=2, default=str))#, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_params = {'title': 'amd ryzen 7 2700x'}\n",
    "# add information to the product\n",
    "products = api.product_finder(product_params)\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product search - manual request\n",
    "# https://keepa.com/#!discuss/t/product-searches/109\n",
    "\n",
    "def make_request(url: str, params: dict) -> Tuple[dict, None] | Tuple[None, str]:\n",
    "\t'''\n",
    "\t\tMakes a request to the url with the given parameters.\n",
    "\t\tReturns the response as a dictionary.\n",
    "\t'''\n",
    "\ttry:\n",
    "\t\tresponse = requests.get(url, params=params)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\treturn response.json(), None\n",
    "\texcept requests.exceptions.HTTPError as err:\n",
    "\t\treturn None, err\n",
    "\n",
    "def search_products(term: str) -> dict:\n",
    "\t'''\n",
    "\t\tSearches for products with the given term.\n",
    "\t\tReturns the response as a dictionary.\n",
    "\t'''\n",
    "\t# /search?key=<yourAccessKey>&domain=<domainId>&type=product&term=<searchTerm>\n",
    "\tbase_url = 'https://api.keepa.com/search'\n",
    "\tparams = {\n",
    "\t\t'key': API_KEY,\n",
    "\t\t'page': 0,\n",
    "\t\t'domain': 1,\n",
    "\t\t'type': 'product',\n",
    "\t\t'term': term\n",
    "\t}\n",
    "\tresponse, err = make_request(base_url, params)\n",
    "\tif err:\n",
    "\t\traise err\n",
    "\tassert response is not None\n",
    "\treturn response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_products_response = search_products('amd ryzen 7 2700x')\n",
    "# print all keys and values except for \"products\" - print just the length of \"products\"\n",
    "for key, value in searched_products_response.items():\n",
    "\tif key != 'products':\n",
    "\t\tprint(f\"{key}: {value}\")\n",
    "\telse:\n",
    "\t\tprint(f\"{key}: {len(value)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_products = searched_products_response[\"products\"]\n",
    "print(f\"products count: {len(searched_products)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_product_ASINs(products: dict) -> None:\n",
    "\t'''\n",
    "\t\tPrints the ASINs of the products in the given dictionary.\n",
    "\t'''\n",
    "\tprint(f\"len: {len(products)}\")\n",
    "\tfor product in products:\n",
    "\t\tprint(f\"{product['asin']}  -  {product['title']}\")\n",
    "\n",
    "print_product_ASINs(searched_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to optimize the search?\n",
    "# - return only n (10) results at a time\n",
    "# - only return a list of product ASINs and titles\n",
    "# - use fuzzy string matching\n",
    "# - return product data only after filtering the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_product = searched_products[0]\n",
    "parsed_csv = parse_csv(single_product['csv'])\n",
    "keys = list(parsed_csv.keys())\n",
    "key_objects = []\n",
    "for i in range(0, len(keys), 3):\n",
    "\t\tkey_objects.append(\n",
    "\t\t\t{\n",
    "\t\t\t\t'time': keys[i],\n",
    "\t\t\t\t'price': keys[i + 1],\n",
    "\t\t\t\t'df': keys[i + 2]\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "print(json.dumps(key_objects, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for key in key_objects:\n",
    "\t# impute missing values by taking the last known value\n",
    "\t# parsed_csv[key[\"price\"]] = parsed_csv[key[\"price\"]].replace(-1, np.nan).fillna(method='ffill')\n",
    "\t# interp_func = interp1d(parsed_csv[key[\"time\"]], parsed_csv[key[\"price\"]], kind='linear', fill_value='extrapolate')\n",
    "\t# parse_csv[key[\"price\"]] = interp_func(parsed_csv[key[\"time\"]])\n",
    "\t\n",
    "\tprice_discrete, date_discrete = discretize(parsed_csv[key[\"price\"]], parsed_csv[key[\"time\"]])\n",
    "\tprice_filled, date_filled, metadata = fill_missing_dates(price_discrete, date_discrete)\n",
    "\t# create a df from the filled values and dates, where the dates are the index\n",
    "\tdf = pd.DataFrame({\"values\": price_filled}, index=date_filled)\n",
    "\t# print(df.head(20))\n",
    "\tdf = df.interpolate(method='linear', limit_direction='both')\n",
    "\t\n",
    "\n",
    "\tinterpolated_dates = df.index\n",
    "\tinterpolated_values = df[\"values\"]\n",
    "\tprint(f\"Key {key['price']} has {metadata['missing_dates_count']} missing dates ({metadata['missing_dates_percentage']}%)\")\n",
    "\tfig.add_trace(go.Scatter(x=interpolated_dates, y=interpolated_values, name=key[\"price\"]))#, mode='markers'))\n",
    "fig.update_layout(title='Price vs Time',\n",
    "\t\t\t\t\t\t\t\t\txaxis_title='Time',\n",
    "\t\t\t\t\t\t\t\t\tyaxis_title='Price',\n",
    "\t\t\t\t\t\t\t\t\tshowlegend=True\n",
    ")\n",
    "# add \n",
    "# fig.update_layout(width=1600, height=1200)\n",
    "# hide all but AMAZON, NEW, USED legend\n",
    "for i in range(3, len(fig.data)):\n",
    "\tfig.data[i].visible = 'legendonly'\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
