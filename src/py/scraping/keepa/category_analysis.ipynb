{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from datetime import datetime\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.colors as colors\n",
    "from bson import json_util\n",
    "import copy\n",
    "\n",
    "# Project imports\n",
    "sys.path.append(os.getcwd())\n",
    "# from src.py.utils.generic_utils import wrapper\n",
    "from src.py.scraping.keepa.keepa_analysis_utils import load_result_object, parse_csv, organize_csv, discretize_csv_smart, get_trends, get_timeseries_from_trends, remove_outliers, remove_outliers_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_domains_root = \"data/keepa/products/domains\"\n",
    "domain = \"1\" # chosen domain\n",
    "# path_domains = os.path.join(path_domains_root, domain)\n",
    "path_categories_json = f\"data/keepa/generated/categories-domain-{domain}.json\" # file containing products grouped by category\n",
    "path_trends = f\"data/keepa/generated/trends\" # root folder containing trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = json.load(open(path_categories_json, \"r\"))\n",
    "print(f\"Number of categories: {len(categories)}\")\n",
    "for category in categories:\n",
    "\tprint(f\"* {category} ({len(categories[category])} products)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with COMPUTER_PROCESSOR category\n",
    "category = \"INTERNAL_SOLID_STATE_DRIVES\"\n",
    "trends = {}\n",
    "time_start = time.time()\n",
    "skipped_product_keys_dict = {}\n",
    "for i, asin in enumerate(categories[category]):\n",
    "\tfilepath = categories[category][asin][\"file\"]\n",
    "\tresult_object = load_result_object(filepath)\n",
    "\tproduct = result_object[\"products\"][0]\n",
    "\tprint(\n",
    "\t    f\"Product {i + 1}/{len(categories[category])} ({asin}): {product['title']}\\r\",\n",
    "\t    end=\"\")\n",
    "\tparsed_csv = parse_csv(product[\"csv\"])\n",
    "\torganized_csv = organize_csv(parsed_csv)\n",
    "\t# csv_no_outliers = organized_csv\n",
    "\tcsv_no_outliers = remove_outliers_csv(organized_csv, max_std_multiplier=3) # =2)\n",
    "\tdiscretize_csv_smart(csv_no_outliers)\n",
    "\ttrends, skipped_product_keys = get_trends(csv_no_outliers, trends, minimum_datapoints=100)\n",
    "\tfor k in skipped_product_keys:\n",
    "\t\tif k not in skipped_product_keys_dict:\n",
    "\t\t\tskipped_product_keys_dict[k] = []\n",
    "\t\tskipped_product_keys_dict[k].append(filepath)\n",
    "\t# TODO: record total keys for product and keys skipped then calculate percentage\n",
    "\t# at the end calculate the number and percentage where all keys were skipped\n",
    "time_end = time.time()\n",
    "print()\n",
    "print(f\"Elapsed time: {round(time_end - time_start, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of skipped products for each key\n",
    "print(\"Number of skipped products for each key:\")\n",
    "for key in skipped_product_keys_dict:\n",
    "\tprint(f\"* {key}: {len(skipped_product_keys_dict[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of days for each key\n",
    "print(\"Number of days for each key:\")\n",
    "for key in trends:\n",
    "\tprint(f\"* {key}: {len(trends[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what are some of these keys even?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_trend_key = \"NEW\"  # \"NEW # \"AMAZON\"\n",
    "amazon_values, amazon_dates = get_timeseries_from_trends(trends,\n",
    "                                                         selected_trend_key,\n",
    "                                                         operation=\"average\")\n",
    "amazon_counts, _ = get_timeseries_from_trends(trends,\n",
    "                       selected_trend_key,\n",
    "                       operation=\"count\")\n",
    "print(f\"Got {len(amazon_values)} values for {selected_trend_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average window 30 days:\n",
    "window = 30 * 1 # 30\n",
    "avg30 = np.ones(window) / window\n",
    "amazon_values_avg30 = np.convolve(amazon_values, avg30, mode='same')\n",
    "\n",
    "# cut off all pairs of dates and values where date is < 2019\n",
    "cutoff_date = datetime(2015, 1, 1) # datetime(2015, 1, 1) # datetime(2019, 1, 1)\n",
    "# cutoff_date = datetime(2015, 1, 1)\n",
    "dates_cutoff_index = 0\n",
    "try:\n",
    "\tdates_cutoff_index = np.where(amazon_dates == cutoff_date)[0][0]\n",
    "except:\n",
    "\tpass\n",
    "amazon_values_cut = amazon_values[dates_cutoff_index:]\n",
    "amazon_dates_cut = amazon_dates[dates_cutoff_index:]\n",
    "amazon_counts_cut = amazon_counts[dates_cutoff_index:]\n",
    "# avg30\n",
    "amazon_dates_avg30 = amazon_dates_cut\n",
    "amazon_values_avg30 = amazon_values_avg30[dates_cutoff_index:]\n",
    "\n",
    "# remove last 30 days from timeseries\n",
    "amazon_dates_cut = amazon_dates_cut[:-30]\n",
    "amazon_values_cut = amazon_values_cut[:-30]\n",
    "amazon_counts_cut = amazon_counts_cut[:-30]\n",
    "# avg30\n",
    "amazon_dates_avg30 = amazon_dates_avg30[:-30]\n",
    "amazon_values_avg30 = amazon_values_avg30[:-30]\n",
    "\n",
    "\n",
    "\n",
    "# Plot timeseries as 2 subplots - top is timeseries, bottom is count for a specific date - they are linked\n",
    "top_row_height = 0.7\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.0125, row_heights=[top_row_height, 1 - top_row_height])\n",
    "\n",
    "# top plot\n",
    "fig.add_trace(go.Scatter(x=amazon_dates_cut, y=amazon_values_cut, name=\"Average price (USD)\"), row=1, col=1)\n",
    "# bottom plot\n",
    "fig.add_trace(go.Scatter(x=amazon_dates_cut, y=amazon_counts_cut, name=\"Count (data points for day)\"), row=2, col=1)\n",
    "\n",
    "# Add moving average in gray line to top plot\n",
    "fig.add_trace(go.Scatter(x=amazon_dates_avg30,\n",
    "                         y=amazon_values_avg30,\n",
    "                         line=dict(color='orange', width=3),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t name=f\"Avg. price ({window} day moving avg.)\"),\n",
    "              row=1,\n",
    "              col=1,\n",
    "\t\t\t\t\t\t\t)\n",
    "\n",
    "# Give title to x axis\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "\n",
    "# Give title to y axis of top plot\n",
    "fig.update_yaxes(title_text=\"Average price (USD)\", row=1, col=1)\n",
    "# Give title to y axis of bottom plot\n",
    "fig.update_yaxes(title_text=\"Count (data points for day)\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(title=f\"Price trends of {len(categories[category]) - len(skipped_product_keys_dict[selected_trend_key])} products in category \\\"{category}\\\" for \\\"{selected_trend_key}\\\" trend key\")\n",
    "# make it wide\n",
    "fig.update_layout(width=1500, height=700)\n",
    "fig.show(renderer=\"browser\")\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* is nice xd\n",
    "\n",
    "# TODO\n",
    "\n",
    "* Which std dev multiplier to use for removing extreme values? Current default is 2x std dev - should we use 2x, 3x, 5x or 10x?\n",
    "* When adding to trends, create a way to specify minimum requirements for a number of data points for a specific trend key in the product object for it to be added to the trends. Default is -1 (no minimum), recommended is 100.\n",
    "\n",
    "# DONE\n",
    "\n",
    "* Remove extreme values from timeseries before adding to trends - get average of all values and remove value,date pairs that are too far from the average (e.g. 3x the average +/-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trends(traces: list[dict],\n",
    "                title: str,\n",
    "                currency: str = \"USD\") -> go.Figure:\n",
    "\t'''\n",
    "\t\tPlots a list of timeseries with the given title\n",
    "\t'''\n",
    "\t# Example element in traces:\n",
    "\t# trace = {\n",
    "\t# \t\"x\": \"timeseries_dates\",\n",
    "\t# \t\"y\": \"timeseries_values\",\n",
    "\t# \t\"counts\": \"timeseries_counts\",\n",
    "\t# \t\"avg30\": {\n",
    "\t# \t\t\"x\": \"timeseries_dates\",\n",
    "\t# \t\t\"y\": \"timeseries_values\",\n",
    "\t# \t},\n",
    "\t# \t\"name\": \"Average price, ...\"\n",
    "\t# \t\"trend_key\": \"NEW\",\n",
    "\t# \t\"operation\": \"average\",\n",
    "\t# }\n",
    "\n",
    "\trows = 2\n",
    "\trows_added = 0\n",
    "\n",
    "\t# Remove traces for RATING and COUNT_REVIEWS (they are plotted separately - below)\n",
    "\ttrace_rating = {}\n",
    "\ttrace_reviews = {}\n",
    "\ttraces_new = []\n",
    "\tfor trace in traces:\n",
    "\t\tif \"RATING\" in trace[\"trend_key\"]:\n",
    "\t\t\ttrace_rating = trace\n",
    "\t\t\trows += 1\n",
    "\t\t\trows_added += 1\n",
    "\t\t\tcontinue\n",
    "\t\tif \"COUNT_REVIEWS\" in trace[\"trend_key\"]:\n",
    "\t\t\ttrace_reviews = trace\n",
    "\t\t\trows += 1\n",
    "\t\t\trows_added += 1\n",
    "\t\t\tcontinue\n",
    "\t\ttraces_new.append(trace)\n",
    "\ttraces = traces_new\n",
    "\n",
    "\ttop_row_height = 0.7\n",
    "\tfig = make_subplots(\n",
    "\t    cols=1,\n",
    "\t    #  rows=len(traces) + 1, # main (top) plot + count plot for each trend\n",
    "\t    rows=rows,\n",
    "\t    shared_xaxes=True,\n",
    "\t    vertical_spacing=0.0125,\n",
    "\t    #  row_heights=[top_row_height] + [1 - top_row_height] * len(traces),\n",
    "\t    # row_heights=[top_row_height, 1 - top_row_height],\n",
    "\t    row_heights=[top_row_height] + [1 - top_row_height] * (rows - 1),\n",
    "\t)\n",
    "\topacity=0.25\n",
    "\t# top plot\n",
    "\t# for i, trace in enumerate(traces):\n",
    "\t# \tfig.add_trace(go.Scatter(x=trace[\"x\"],\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t y=trace[\"y\"],\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t name=trace[\"name\"],\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t line=dict(width=1, color=colors.qualitative.Plotly[i]),\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t opacity=opacity, # 0.5\n",
    "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t ),\n",
    "\t# \t\t\t\t\t\t\t\trow=1,\n",
    "\t# \t\t\t\t\t\t\t\tcol=1,\n",
    "\t# \t)\n",
    "\t# Add moving average line to top plot (random color)\n",
    "\tfor i, trace in enumerate(traces):\n",
    "\t\tfig.add_trace(\n",
    "\t\t    go.Scatter(\n",
    "\t\t        x=trace[\"avg30\"][\"x\"],\n",
    "\t\t        y=trace[\"avg30\"][\"y\"],\n",
    "\t\t        name=f\"Avg{window} ({trace['name']})\",\n",
    "\t\t        line=dict(width=3, color=colors.qualitative.Plotly[i]),\n",
    "\t\t    ),\n",
    "\t\t    row=1,\n",
    "\t\t    col=1,\n",
    "\t\t)\n",
    "\t# bottom plots (count)\n",
    "\tfor i, trace in enumerate(traces):\n",
    "\t\tfig.add_trace(\n",
    "\t\t    go.Scatter(\n",
    "\t\t        x=trace[\"x\"],\n",
    "\t\t        y=trace[\"counts\"],\n",
    "\t\t        name=f\"Count ({trace['name']})\",\n",
    "\t\t        line=dict(width=1, color=colors.qualitative.Plotly[i]),\n",
    "\t\t    ),\n",
    "\t\t    # row=i + 2,\n",
    "\t\t    row=2,\n",
    "\t\t    col=1,\n",
    "\t\t)\n",
    "\t\tif i == len(\n",
    "\t\t    traces\n",
    "\t\t) - rows_added + 1:  # remove this if you want to plot all counts, not just prices\n",
    "\t\t\tbreak\n",
    "\trows_plotted = 0  # extra rows plotted\n",
    "\t# reviews\n",
    "\tif trace_reviews != {}:\n",
    "\t\tfig.add_trace(\n",
    "\t\t    go.Scatter(\n",
    "\t\t        # x=trace_reviews[\"x\"],\n",
    "\t\t        # y=trace_reviews[\"y\"],\n",
    "\t\t        x=trace_reviews[\"avg30\"][\"x\"],\n",
    "\t\t\t\t\t\ty=trace_reviews[\"avg30\"][\"y\"],\n",
    "\t\t        name=f\"Reviews ({trace_reviews['name']})\",\n",
    "\t\t        line=dict(width=1, color=colors.qualitative.Plotly[0]),\n",
    "\t\t    ),\n",
    "\t\t    row=rows - rows_added + rows_plotted + 1,\n",
    "\t\t    col=1,\n",
    "\t\t)\n",
    "\t\t# add y axis title\n",
    "\t\tfig.update_yaxes(title_text=f\"Avg. reviews per day\",\n",
    "\t\t                 row=rows - rows_added + rows_plotted + 1,\n",
    "\t\t                 col=1)\n",
    "\t\trows_plotted += 1\n",
    "\t# rating\n",
    "\tif trace_rating != {}:\n",
    "\t\tfig.add_trace(\n",
    "\t\t    go.Scatter(\n",
    "\t\t        # x=trace_rating[\"x\"],\n",
    "\t\t        # y=trace_rating[\"y\"],\n",
    "\t\t        x=trace_rating[\"avg30\"][\"x\"],\n",
    "\t\t        y=trace_rating[\"avg30\"][\"y\"],\n",
    "\t\t        name=f\"Rating ({trace_rating['name']})\",\n",
    "\t\t        line=dict(width=1, color=colors.qualitative.Plotly[1]),\n",
    "\t\t    ),\n",
    "\t\t    row=rows - rows_added + rows_plotted + 1,\n",
    "\t\t    col=1,\n",
    "\t\t)\n",
    "\t\t# add y axis title\n",
    "\t\tfig.update_yaxes(title_text=f\"Average rating\",\n",
    "\t\t                 row=rows - rows_added + rows_plotted + 1,\n",
    "\t\t                 col=1)\n",
    "\t\trows_plotted += 1\n",
    "\t# Give title to x axis\n",
    "\t# fig.update_xaxes(title_text=\"Date\", row=len(traces) + 1, col=1)\n",
    "\tfig.update_xaxes(title_text=\"Date\", row=rows, col=1)\n",
    "\t# Give title to y axis of top plot\n",
    "\tfig.update_yaxes(title_text=f\"Average price ({currency})\", row=1, col=1)\n",
    "\t# Give title to y axis of bottom plots\n",
    "\tfor i, trace in enumerate(traces):\n",
    "\t\t# fig.update_yaxes(title_text=f\"Count ({trace['name']})\", row=i + 2, col=1)\n",
    "\t\tfig.update_yaxes(title_text=f\"Data points per day\", row=i + 2, col=1)\n",
    "\t\tbreak\n",
    "\tfig.update_layout(title=title)\n",
    "\t# Scale it as width=1500, height=700+100*len(traces)\n",
    "\t# fig.update_layout(width=1500, height=900 + 100 * len(traces))\n",
    "\tfig.update_layout(width=1500, height=900 + (rows - 2) * 100)\n",
    "\treturn fig\n",
    "\n",
    "\n",
    "def get_trend_traces(\n",
    "    trends: dict[str, dict[np.datetime64, npt.NDArray[np.float64]]],\n",
    "    trend_keys: list[str],\n",
    "    operations: list[str],\n",
    "    window: int = 30 * 1,\n",
    "    cutoff_date: datetime = datetime(2019, 1, 1)\n",
    ") -> list[dict]:\n",
    "\t'''\n",
    "\t\tGets a list of traces to plot from the given trends dictionary and settings\n",
    "\t'''\n",
    "\ttraces = []\n",
    "\tfor trend_key, operation in zip(trend_keys, operations):\n",
    "\t\tvalues, dates = get_timeseries_from_trends(trends,\n",
    "\t\t                                           trend_key,\n",
    "\t\t                                           operation=operation)\n",
    "\t\tcounts, _ = get_timeseries_from_trends(trends,\n",
    "\t\t                                       trend_key,\n",
    "\t\t                                       operation=\"count\")\n",
    "\t\t# moving average window 30 days:\n",
    "\t\tavg30 = np.ones(window) / window\n",
    "\t\tvalues_avg30 = np.convolve(values, avg30, mode='same')\n",
    "\t\t# cut off all pairs of dates and values where date is < 2019\n",
    "\t\tdates_cutoff_index = 0\n",
    "\t\t# try:\n",
    "\t\t# \tdates_cutoff_index = np.where(dates == cutoff_date)[0][0]\n",
    "\t\t# except:\n",
    "\t\t# \tpass\n",
    "\t\tfor i, date in enumerate(dates):\n",
    "\t\t\tif date >= cutoff_date:\n",
    "\t\t\t\tdates_cutoff_index = i\n",
    "\t\t\t\tbreak\n",
    "\t\tvalues_cut = values[dates_cutoff_index:]\n",
    "\t\tdates_cut = dates[dates_cutoff_index:]\n",
    "\t\tcounts_cut = counts[dates_cutoff_index:]\n",
    "\t\t# avg30\n",
    "\t\tdates_avg30 = dates_cut\n",
    "\t\tvalues_avg30 = values_avg30[dates_cutoff_index:]\n",
    "\t\t# remove last {window} days from timeseries\n",
    "\t\tdates_cut = dates_cut[:-window]\n",
    "\t\tvalues_cut = values_cut[:-window]\n",
    "\t\t# avg30\n",
    "\t\tdates_avg30 = dates_avg30[:-window]\n",
    "\t\tvalues_avg30 = values_avg30[:-window]\n",
    "\t\t# add trace\n",
    "\t\ttraces.append({\n",
    "\t\t    \"x\": dates_cut,\n",
    "\t\t    \"y\": values_cut,\n",
    "\t\t    \"counts\": counts_cut,\n",
    "\t\t    \"avg30\": {\n",
    "\t\t        \"x\": dates_avg30,\n",
    "\t\t        \"y\": values_avg30,\n",
    "\t\t    },\n",
    "\t\t    \"name\": f\"{trend_key} ({operation})\",\n",
    "\t\t    \"trend_key\": trend_key,\n",
    "\t\t    \"operation\": operation,\n",
    "\t\t})\n",
    "\treturn traces\n",
    "\n",
    "# currency_map = {\n",
    "# \t\"1\": \"USD\", # TODO: add others\n",
    "# }\n",
    "# domain = \"1\"\n",
    "# # category = \"VIDEO_CARD\"\n",
    "# title = f\"Trends of {len(categories[category])} products for category \\\"{category}\\\"\"\n",
    "# currency = currency_map[domain]\n",
    "# window = 30 * 6 # 30 days # sometimes good to set as 30 * 6 (6 months) for smoother trends\n",
    "# cutoff_date = datetime(2017, 1, 7) # datetime(2019, 1, 7)\n",
    "# trend_keys_operations = [\n",
    "# \t(\"NEW\", \"average\"),\n",
    "# \t(\"USED\", \"average\"),\n",
    "# \t(\"AMAZON\", \"average\"),\n",
    "# \t(\"EBAY_NEW_SHIPPING\", \"average\"),\n",
    "# \t(\"EBAY_USED_SHIPPING\", \"average\"),\n",
    "# \t(\"RATING\", \"average\"),\n",
    "# \t(\"COUNT_REVIEWS\", \"average\"),\n",
    "# ]\n",
    "# # trend_keys = [\n",
    "# # \t\"NEW\",\n",
    "# # \t\"USED\",\n",
    "# # \t\"AMAZON\",\n",
    "# # \t\"EBAY_NEW_SHIPPING\",\n",
    "# # \t\"EBAY_USED_SHIPPING\",\n",
    "# # ]\n",
    "# # operations = [\n",
    "# # \t\"average\",\n",
    "# # \t\"average\",\n",
    "# # \t\"average\",\n",
    "# # \t\"average\",\n",
    "# # \t\"average\",\n",
    "# # ]\n",
    "# trend_keys = [t[0] for t in trend_keys_operations]\n",
    "# operations = [t[1] for t in trend_keys_operations]\n",
    "# trend_traces = get_trend_traces(trends, trend_keys, operations, window=window, cutoff_date=cutoff_date)\n",
    "# fig = plot_trends(trend_traces, title, currency)\n",
    "# fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate trends for all categories and save to file (for each category) (for selected domain)\n",
    "# so it won't have to be calculated again (unless the data or algorithm changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends_for_category(category: dict) -> dict:\n",
    "\t'''\n",
    "\t\tGets trends for a category\n",
    "\t'''\n",
    "\ttrends = {}\n",
    "\tskipped_product_keys_dict = {}\n",
    "\ttime_start = time.time()\n",
    "\tfor i, asin in enumerate(category):\n",
    "\t\tfilepath = category[asin][\"file\"]\n",
    "\t\tresult_object = load_result_object(filepath)\n",
    "\t\tproduct = result_object[\"products\"][0]\n",
    "\t\tprint(f\"Product {i + 1}/{len(category)} ({asin}): {product['title']}\\r\",\n",
    "\t\t      end=\"\")\n",
    "\t\tparsed_csv = parse_csv(product[\"csv\"])\n",
    "\t\torganized_csv = organize_csv(parsed_csv)\n",
    "\t\t# csv_no_outliers = organized_csv\n",
    "\t\tcsv_no_outliers = remove_outliers_csv(organized_csv, max_std_multiplier=3)\n",
    "\t\tdiscretize_csv_smart(csv_no_outliers)\n",
    "\t\ttrends, skipped_product_keys = get_trends(csv_no_outliers,\n",
    "\t\t                                          trends,\n",
    "\t\t                                          minimum_datapoints=100)\n",
    "\t\tfor k in skipped_product_keys:\n",
    "\t\t\tif k not in skipped_product_keys_dict:\n",
    "\t\t\t\tskipped_product_keys_dict[k] = []\n",
    "\t\t\tskipped_product_keys_dict[k].append(filepath)\n",
    "\t\t# TODO: record total keys for product and keys skipped then calculate percentage\n",
    "\t\t# at the end calculate the number and percentage where all keys were skipped\n",
    "\tprint()\n",
    "\ttime_end = time.time()\n",
    "\ttime_elapsed = round(time_end - time_start, 2)\n",
    "\t# print(f\"Elapsed time: {time_elapsed} seconds\")\n",
    "\treturn_dict = {\n",
    "\t    \"trends\": trends,\n",
    "\t    \"skipped_product_keys_dict\": skipped_product_keys_dict,\n",
    "\t    \"time_elapsed\": time_elapsed,\n",
    "\t}\n",
    "\treturn return_dict\n",
    "\n",
    "\n",
    "def get_categories_object(categories_path) -> dict:\n",
    "\t'''\n",
    "\t\tGets categories object from a file\n",
    "\t'''\n",
    "\tcategories = {}\n",
    "\twith open(categories_path, \"r\") as f:\n",
    "\t\tcategories = json.load(f)\n",
    "\treturn categories\n",
    "\n",
    "\n",
    "def save_trends_result(return_dict: dict, path_trends: str) -> None:\n",
    "\t# if directory portion of the path doesn't exist, create it\n",
    "\tif not os.path.exists(os.path.dirname(path_trends)):\n",
    "\t\tos.makedirs(os.path.dirname(path_trends))\n",
    "\t# # safe_string = json_util.dumps(return_dict, indent=2) # using bson.json_util.dumps to handle datetime objects\n",
    "\t# # save trends to json file\n",
    "\t# # Nothing will serialize the object, as the unfamiliar object (datetime) is used as keys in the dictionary.\n",
    "\t# safe_return_dict = {}\n",
    "\t# # deep copy the return_dict\n",
    "\t# safe_return_dict = copy.deepcopy(return_dict)\n",
    "\t# for trend_key in return_dict[\"trends\"]:\n",
    "\t# \tfor date in return_dict[\"trends\"][trend_key]:\n",
    "\t# \t\tsafe_date = str(date)\n",
    "\t# \t\tsafe_return_dict[\"trends\"][trend_key][safe_date] = safe_return_dict[\n",
    "\t# \t\t    \"trends\"][trend_key][date]\n",
    "\t# \t\tdel safe_return_dict[\"trends\"][trend_key][date]\n",
    "\t# safe_string = json_util.dumps(safe_return_dict, indent=2)\n",
    "\t# with open(path_trends, \"w\") as f:\n",
    "\t# \tf.write(safe_string)\n",
    "\twith open(path_trends, \"wb\") as f:\n",
    "\t\tnp.save(f, return_dict) # type: ignore\n",
    "\ta = 0\n",
    "\n",
    "\n",
    "def process_trends_for_domain(domain: str) -> dict:\n",
    "\t'''\n",
    "\t\tProcesses trends for all categories in a domain\n",
    "\t'''\n",
    "\tpath_categories_json = f\"data/keepa/generated/categories-domain-{domain}.json\"  # file containing products grouped by category\n",
    "\tpath_trends = f\"data/keepa/generated/trends\"  # root folder containing trends\n",
    "\tcategories = get_categories_object(path_categories_json)\n",
    "\tdomain_trends = {}\n",
    "\tskipped_product_keys_dict = {}\n",
    "\ttime_elapsed = 0\n",
    "\tfor i, category in enumerate(categories):\n",
    "\t\tprint(\n",
    "\t\t    f\"Processing category \\\"{category}\\\" ({len(categories[category])} products) ({i + 1}/{len(categories)})\"\n",
    "\t\t)\n",
    "\t\tfilepath = os.path.join(*[path_trends, domain, f\"{category}.npy\"])\n",
    "\t\tif os.path.exists(filepath):\n",
    "\t\t\tprint(\n",
    "\t\t\t    f\"Skipping category \\\"{category}\\\" - already exists at \\\"{filepath}\\\" - loading...\"\n",
    "\t\t\t)\n",
    "\t\t\treturn_dict = np.load(filepath, allow_pickle=True).item()\n",
    "\t\t\tdomain_trends[category] = return_dict[\"trends\"]\n",
    "\t\t\tskipped_product_keys_dict[category] = return_dict[\n",
    "\t\t\t    \"skipped_product_keys_dict\"]\n",
    "\t\t\ttime_elapsed += return_dict[\"time_elapsed\"]\n",
    "\t\t\tprint(\n",
    "\t\t\t    f\"Elapsed time (loaded) for category \\\"{category}\\\": {return_dict['time_elapsed']} seconds\"\n",
    "\t\t\t)\n",
    "\t\t\tprint()\n",
    "\t\t\tcontinue\n",
    "\t\t# if len(categories[category]) > 200: # debug\n",
    "\t\t# \tcontinue\n",
    "\t\treturn_dict = get_trends_for_category(categories[category])\n",
    "\t\tsave_trends_result(return_dict, filepath)\n",
    "\t\tdomain_trends[category] = return_dict[\"trends\"]\n",
    "\t\tskipped_product_keys_dict[category] = return_dict[\n",
    "\t\t    \"skipped_product_keys_dict\"]\n",
    "\t\ttime_elapsed += return_dict[\"time_elapsed\"]\n",
    "\t\tprint(\n",
    "\t\t    f\"Elapsed time for category \\\"{category}\\\": {return_dict['time_elapsed']} seconds\"\n",
    "\t\t)\n",
    "\t\tprint()\n",
    "\tprint(f\"Total elapsed time: {time_elapsed} seconds\")\n",
    "\treturn_dict = {\n",
    "\t    \"trends\": domain_trends,\n",
    "\t    \"skipped_product_keys_dict\": skipped_product_keys_dict,\n",
    "\t    \"time_elapsed\": time_elapsed,\n",
    "\t}\n",
    "\t# Save trends for domain to file\n",
    "\tsave_trends_result(\n",
    "\t    return_dict,\n",
    "\t    os.path.join(*[path_trends, f\"all-trends-domain-{domain}.npy\"]))\n",
    "\treturn return_dict\n",
    "\n",
    "# Uncomment when debugging:\n",
    "# domain = \"1\" # chosen domain (US)\n",
    "# domain_trends_results = process_trends_for_domain(domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_all = domain_trends_results[\"trends\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test load of numpy file\n",
    "test_category = np.load(\n",
    "    \"data/keepa/generated/trends/1/EXTERNAL_SOLID_STATE_DRIVES.npy\",\n",
    "    allow_pickle=True).item()\n",
    "print(f\"Trend keys:\")\n",
    "for trend_key in test_category[\"trends\"]:\n",
    "\tprint(f\"* {trend_key}\")\n",
    "# looks good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"1\" # chosen domain (US)\n",
    "domain_trends_results = process_trends_for_domain(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trends = domain_trends_results[\"trends\"]\n",
    "categories = get_categories_object(\n",
    "    f\"data/keepa/generated/categories-domain-{domain}.json\")\n",
    "print(f\"Number of categories: {len(categories)}\")\n",
    "for category in categories:\n",
    "\tprint(f\"* {category} ({len(categories[category])} products)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_map = {\n",
    "    \"1\": \"USD\",  # TODO: add others\n",
    "}\n",
    "domain_map = {\n",
    "  \"1\": \"US\",\n",
    "}\n",
    "# domain = \"1\" # defined above when loading / processing trends\n",
    "category = \"VIDEO_CARD\"\n",
    "trends = all_trends[category]\n",
    "title = f\"Trends of {len(categories[category])} products for category \\\"{category}\\\" (Amazon {domain_map[domain]})\"\n",
    "currency = currency_map[domain]\n",
    "window = 30 * 3 # 30 days # sometimes good to set as 30 * 6 (6 months) for smoother trends\n",
    "cutoff_date = datetime(2017, 1, 7) # datetime(2019, 1, 7)\n",
    "trend_keys_operations = [\n",
    " (\"NEW\", \"average\"),\n",
    " (\"USED\", \"average\"),\n",
    " (\"AMAZON\", \"average\"),\n",
    " (\"EBAY_NEW_SHIPPING\", \"average\"),\n",
    " (\"EBAY_USED_SHIPPING\", \"average\"),\n",
    " (\"RATING\", \"average\"),\n",
    " (\"COUNT_REVIEWS\", \"average\"),\n",
    "]\n",
    "# trend_keys = [\n",
    "# \t\"NEW\",\n",
    "# \t\"USED\",\n",
    "# \t\"AMAZON\",\n",
    "# \t\"EBAY_NEW_SHIPPING\",\n",
    "# \t\"EBAY_USED_SHIPPING\",\n",
    "# ]\n",
    "# operations = [\n",
    "# \t\"average\",\n",
    "# \t\"average\",\n",
    "# \t\"average\",\n",
    "# \t\"average\",\n",
    "# \t\"average\",\n",
    "# ]\n",
    "trend_keys = [t[0] for t in trend_keys_operations]\n",
    "operations = [t[1] for t in trend_keys_operations]\n",
    "trend_traces = get_trend_traces(trends, trend_keys, operations, window=window, cutoff_date=cutoff_date)\n",
    "fig = plot_trends(trend_traces, title, currency)\n",
    "fig.show(renderer=\"browser\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all for a specific setting to files (this is a self-contained block)\n",
    "domain = \"1\" # chosen domain (US)\n",
    "domain_trends_results = process_trends_for_domain(domain)\n",
    "all_trends = domain_trends_results[\"trends\"]\n",
    "categories = get_categories_object(\n",
    "    f\"data/keepa/generated/categories-domain-{domain}.json\")\n",
    "# print(f\"Number of categories: {len(categories)}\")\n",
    "# for category in categories:\n",
    "# \tprint(f\"* {category} ({len(categories[category])} products)\")\n",
    "currency_map = {\n",
    "\t\t\t\"1\": \"USD\",  # TODO: add others\n",
    "}\n",
    "domain_map = {\n",
    "\t\"1\": \"US\",\n",
    "}\n",
    "trend_keys_operations = [\n",
    "\t(\"NEW\", \"average\"),\n",
    "\t(\"USED\", \"average\"),\n",
    "\t(\"AMAZON\", \"average\"),\n",
    "\t(\"EBAY_NEW_SHIPPING\", \"average\"),\n",
    "\t(\"EBAY_USED_SHIPPING\", \"average\"),\n",
    "\t(\"RATING\", \"average\"),\n",
    "\t(\"COUNT_REVIEWS\", \"average\"),\n",
    "\t]\n",
    "trend_keys = [t[0] for t in trend_keys_operations]\n",
    "operations = [t[1] for t in trend_keys_operations]\n",
    "currency = currency_map[domain]\n",
    "window = 30 * 3 # 30 days # sometimes good to set as 30 * 6 (6 months) for smoother trends ; 30 * 3 is smoothing by quarter\n",
    "cutoff_date = datetime(2017, 1, 7) # datetime(2019, 1, 7)\n",
    "print(f\"\\nGenerating plots for all categories...\\n\")\n",
    "for i, category in enumerate(categories):\n",
    "\ttry:\n",
    "\t\tprint(f\"Plotting \\\"{category}\\\" ({len(categories[category])} products) ({i + 1}/{len(categories)})\")\n",
    "\t\ttrends = all_trends[category]\n",
    "\t\ttitle = f\"Trends of {len(categories[category])} products for category \\\"{category}\\\" (Amazon {domain_map[domain]})\"\n",
    "\t\ttrend_traces = get_trend_traces(trends, trend_keys, operations, window=window, cutoff_date=cutoff_date)\n",
    "\t\tfig = plot_trends(trend_traces, title, currency)\n",
    "\t\tfig.show(renderer=\"browser\")\n",
    "\t\tplot_path = f\"data/keepa/generated/plots/{domain}/{category}.html\"\n",
    "\t\tif not os.path.exists(os.path.dirname(plot_path)):\n",
    "\t\t\tos.makedirs(os.path.dirname(plot_path))\n",
    "\t\tprint(f\"Saving html...\")\n",
    "\t\tfig.write_html(plot_path)\n",
    "\t\tprint(f\"Saving png...\")\n",
    "\t\tfig.write_image(plot_path.replace(\".html\", \".png\"), scale=2)\n",
    "\t\tprint(f\"Saved!\")\n",
    "\t\tprint()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f\"Error plotting \\\"{category}\\\" ({len(categories[category])} products) ({i + 1}/{len(categories)})\")\n",
    "\t\tprint(e)\n",
    "\t\tprint()\n",
    "print(\"ALL DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
