{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# World Economic Outlook Database\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.imf.org/en/Publications/WEO/weo-database/2023/October/download-entire-database\n",
    "year = 2023\n",
    "month = \"Oct\"\n",
    "\n",
    "url_base = f\"https://www.imf.org/-/media/Files/Publications/WEO/WEO-Database/{year}\"\n",
    "url_by_countries = f\"{url_base}/WEO{month}{year}all.ashx\" # 9 MB ; .xls\n",
    "url_by_country_groups = f\"{url_base}/WEO{month}{year}alla.ashx\" # 577 KB ; .xls\n",
    "url_sdmx_data = f\"{url_base}/WEO{month}{year}-SDMXData.ashx\" # 24 MB ; .zip\n",
    "url_sdmx_data_structure_definition = f\"{url_base}/weo{month.lower()}{year}-sdmx-dsd.ashx\" # 1 MB ; .xml\n",
    "url_custom_query_country_groups_all = \"https://www.imf.org/imf/weodatabase/downloadreport?a=1&c=001,110,163,119,123,998,510,200,505,903,205,400,603,&s=NGDP_RPCH,NGDP_RPCHMK,NGDPD,PPPGDP,NGDP_D,NGDPRPPPPC,PPPPC,NGAP_NPGDP,PPPSH,NID_NGDP,NGSD_NGDP,PCPIPCH,PCPIEPCH,TRADEPCH,TM_RPCH,TMG_RPCH,TX_RPCH,TXG_RPCH,TTPCH,TTTPCH,TXGM_D,TXGM_DPCH,LUR,LE,GGR_NGDP,GGX_NGDP,GGXCNL_NGDP,GGSB_NPGDP,GGXONLB_NGDP,GGXWDN_NGDP,GGXWDG_NGDP,BCA,BCA_NGDPD,BM,BX,BF,BFD,BFP,BFF,BFO,BFRA,D,D_NGDPD,D_BX,DS,DS_NGDPD,DS_BX,DSI,DSI_NGDPD,DSI_BX,DSP,DSP_NGDPD,DSP_BX,PALLFNFW,PNFUELW,PINDUW,POILAPSP,POILBRE,POILDUB,POILWTI,PNRGW,POILAPSPW,PNGASW,PNGASEU,PNGASJP,PNGASUS,PCOALW,PCOALAU,PCOALSA,PFANDBW,PFOODW,PCEREW,PWHEAMT,PMAIZMT,PRICENPQ,PBARL,PVOILW,PSOYB,PSMEA,PSOIL,PROIL,PPOIL,PSUNO,POLVOIL,PFISH,PGNUTS,PMEATW,PBEEF,PLAMB,PPORK,PPOULT,PSEAFW,PSALM,PSHRI,PSUGAW,PSUGAISA,PSUGAUSA,PBANSOP,PORANG,PBEVEW,PCOFFW,PCOFFOTM,PCOFFROB,PCOCO,PTEA,PRAWMW,PTIMBW,PHARDW,PLOGSK,PSAWMAL,PSOFTW,PLOGORE,PSAWORE,PCOTTIND,PWOOLW,PWOOLF,PWOOLC,PRUBB,PHIDE,PMETAW,PCOPP,PALUM,PIORECR,PTIN,PNICK,PZINC,PLEAD,PURAN,&sy=1980&ey=2028&ssm=1&scsm=1&scc=1&ssd=1&ssc=1&sic=0&sort=country&ds=.&br=1&wsid=69dccfdb-9723-44a6-99d3-6a0c1eac4300\" # 1 MB ; .xls\n",
    "\n",
    "path_output_root = \"data/scraped/imf\"\n",
    "path_output_weo = os.path.join(path_output_root, \"weo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_ashx(url: str, destination_directory: str, filename: Optional[str] = None) -> str:\n",
    "\t'''\n",
    "\t\tDownload a file from a URL to a destination directory and returns the filepath\n",
    "\t'''\n",
    "\tos.makedirs(destination_directory, exist_ok=True)\n",
    "\tif filename is None:\n",
    "\t\tfilename = url.split(\"/\")[-1]\n",
    "\tfilepath = os.path.join(destination_directory, filename)\n",
    "\n",
    "\thead = requests.head(url)\n",
    "\tcontent_type = head.headers.get(\"content-type\", \"\")\n",
    "\t\n",
    "\tif \"application/vnd.ms-excel\" in content_type:\n",
    "\t\tfilepath = filepath.replace(\".ashx\", \".xls\")\n",
    "\telif \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\" in content_type:\n",
    "\t\tfilepath = filepath.replace(\".ashx\", \".xlsx\")\n",
    "\telif \"application/zip\" in content_type or \"application/x-zip-compressed\" in content_type:\n",
    "\t\tfilepath = filepath.replace(\".ashx\", \".zip\")\n",
    "\telse:\n",
    "\t\traise Exception(f\"Unsupported content type: {content_type}\")\n",
    "\tif os.path.exists(filepath):\n",
    "\t\tprint(f\"File already exists: '{filepath}'\")\n",
    "\t\treturn filepath\n",
    "\t\n",
    "\tresponse = requests.get(url)\n",
    "\n",
    "\tif response.status_code != 200:\n",
    "\t\traise Exception(f\"Failed to download file: {url}\")\n",
    "\t\n",
    "\twith open(filepath, \"wb\") as f:\n",
    "\t\tf.write(response.content)\n",
    "\tprint(f\"Downloaded file: '{filepath}'\")\n",
    "\treturn filepath\n",
    "\n",
    "def extract_file(filepath: str, destination: str) -> list[str]:\n",
    "\t'''\n",
    "\t\tExtract a file to a destination directory\n",
    "\t'''\n",
    "\tos.makedirs(destination, exist_ok=True)\n",
    "\tnamelist = []\n",
    "\t\n",
    "\tif not filepath.endswith(\".zip\"):\n",
    "\t\traise Exception(f\"Unsupported file type: {filepath}\")\n",
    "\t\n",
    "\twith zipfile.ZipFile(filepath, \"r\") as zip_ref:\n",
    "\t\t# zip_ref.extractall(destination)\n",
    "\t\tcount_failed = 0\n",
    "\t\tcount_success = 0\n",
    "\t\tfor name in zip_ref.namelist():\n",
    "\t\t\ttry:\n",
    "\t\t\t\tzip_ref.extract(name, destination)\n",
    "\t\t\t\tprint(f\"Extracted file '{name}' from '{filepath}' to '{destination}'\")\n",
    "\t\t\t\tnamelist.append(name)\n",
    "\t\t\t\tcount_success += 1\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(f\"Failed to extract file '{name}' from '{filepath}' to '{destination}': {e}\")\n",
    "\t\t\t\tcount_failed += 1\n",
    "\t\tprint(f\"Extracted {count_success} files. Failed to extract {count_failed} files.\")\n",
    "\t\n",
    "\treturn namelist\n",
    "\n",
    "def fix_xls(filepath: str) -> None:\n",
    "\t'''\n",
    "\t\tFix an .xls file by removing all ordinal 0 characters\n",
    "\t'''\n",
    "\ttext = \"\"\n",
    "\twith open(filepath, \"r\") as f:\n",
    "\t\ttext = f.read()\n",
    "\ttext = text.replace(\"\\x00\", \"\")\n",
    "\twith open(filepath, \"w\") as f:\n",
    "\t\tf.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all files\n",
    "filepath_by_countries = download_file_ashx(url_by_countries, path_output_weo)\n",
    "filepath_by_country_groups = download_file_ashx(url_by_country_groups, path_output_weo)\n",
    "filepath_sdmx_data = download_file_ashx(url_sdmx_data, path_output_weo)\n",
    "filepath_sdmx_data_structure_definition = download_file_ashx(url_sdmx_data_structure_definition, path_output_weo)\n",
    "filepath_custom_query_country_groups_all = download_file_ashx(url_custom_query_country_groups_all, path_output_weo, \"weo-custom-query-country-groups-all.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract filepath_sdmx_data\n",
    "unzipped_files = extract_file(filepath_sdmx_data, path_output_weo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the path with pandas (it's an .xls file)\n",
    "# df = pd.read_excel(filepath_custom_query_country_groups_all, sheet_name=\"WEO October 2023 By Country Groups (custom query)\", header=0, engine=\"xlrd\")\n",
    "# gives error: XLRDError: Unsupported format, or corrupt file: Expected BOF record; found b'W\\x00E\\x00O\\x00 \\x00'\n",
    "# Try loading as csv with tab delimiter\n",
    "filepath_custom_query_country_groups_all = filepath_custom_query_country_groups_all.replace(\".xls\", \".csv\")\n",
    "df = pd.read_csv(filepath_custom_query_country_groups_all, sep=\"\\t\", header=0, engine=\"python\")\n",
    "# remove all even rows\n",
    "df = df.iloc[::2]\n",
    "# reindex\n",
    "df = df.reset_index(drop=True)\n",
    "# all text in all fields is for some reason formatted as \n",
    "# print header\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_custom_query_country_groups_all = filepath_custom_query_country_groups_all.replace(\".xls\", \".csv\")\n",
    "# read contents of csv file\n",
    "text = \"\"\n",
    "with open(filepath_custom_query_country_groups_all, \"r\") as f:\n",
    "\ttext = f.read()\n",
    "# print(text[:1000])\n",
    "# iterate over all characters and print their unicode code point\n",
    "# for i, c in enumerate(text):\n",
    "# \t# print(ord(c), end=\" \")\n",
    "# \tprint(f\"'{c}': {ord(c)}\")\n",
    "# \tif i > 100:\n",
    "# \t\tbreak\n",
    "# remove all ordinal 0 characters\n",
    "text = text.replace(\"\\x00\", \"\")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the text as a csv (dataframe with tab delimiter)\n",
    "df = pd.read_csv(BytesIO(text.encode()), sep=\"\\t\", header=0)#, engine=\"python\")\n",
    "# iterate over columns and change all of the columns with years to floats\n",
    "for column in df.columns:\n",
    "\tif column.isnumeric():\n",
    "\t\t# print(f\"Converting column '{column}' to float\")\n",
    "\t\tdf[column] = df[column].str.replace(\",\", \"\") # remove commas\n",
    "\t\tdf[column] = df[column].astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_xls(filepath_custom_query_country_groups_all)\n",
    "df = pd.read_csv(filepath_custom_query_country_groups_all, sep=\"\\t\", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_df(df: pd.DataFrame) -> dict:\n",
    "\t'''\n",
    "\t\tConvert a dataframe to a dictionary\n",
    "\t'''\n",
    "\tdata = {}\n",
    "\tdata[\"subjects\"] = {} # translation table from subject code to subject descriptor, subject notes, units, and scale\n",
    "\tdata[\"country_groups\"] = {} # translation table from country group code to country group name, and data over time for each subject\n",
    "\tyear_columns = [column for column in df.columns if column.isnumeric()]\n",
    "\tdata[\"years\"] = list(year_columns)\n",
    "\tyear_start = int(year_columns[0])\n",
    "\tyear_end = int(year_columns[-1])\n",
    "\tdata[\"year_start\"] = year_start\n",
    "\tdata[\"year_end\"] = year_end\n",
    "\t# iterate over rows\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\t# get values\n",
    "\t\tcountry_group_code = row[\"WEO Country Group Code\"]\n",
    "\t\tif len(country_group_code) != 3: # skip row with \"International Monetary Fund, World Economic Outlook Database, October 2023\"\n",
    "\t\t\tcontinue\n",
    "\t\tcountry_group_name = row[\"Country Group Name\"]\n",
    "\t\tsubject_code = row[\"WEO Subject Code\"]\n",
    "\t\tsubject_descriptor = row[\"Subject Descriptor\"]\n",
    "\t\tsubject_notes = row[\"Subject Notes\"]\n",
    "\t\tunits = row[\"Units\"]\n",
    "\t\tscale = row[\"Scale\"]\n",
    "\t\ttimeseries = row[year_columns].values\n",
    "\t\t# replace NaN with None\n",
    "\t\tcountry_group_code = country_group_code if not pd.isna(country_group_code) else None\n",
    "\t\tcountry_group_name = country_group_name if not pd.isna(country_group_name) else None\n",
    "\t\tsubject_code = subject_code if not pd.isna(subject_code) else None\n",
    "\t\tsubject_descriptor = subject_descriptor if not pd.isna(subject_descriptor) else None\n",
    "\t\tsubject_notes = subject_notes if not pd.isna(subject_notes) else None\n",
    "\t\tunits = units if not pd.isna(units) else None\n",
    "\t\tscale = scale if not pd.isna(scale) else None\n",
    "\t\ttimeseries = [None if pd.isna(value) else value for value in timeseries]\n",
    "\t\t# add to data\n",
    "\t\tif country_group_code not in data[\"country_groups\"]:\n",
    "\t\t\tdata[\"country_groups\"][country_group_code] = {}\n",
    "\t\tdata[\"country_groups\"][country_group_code][\"code\"] = country_group_code\n",
    "\t\tdata[\"country_groups\"][country_group_code][\"name\"] = country_group_name\n",
    "\t\tif \"subjects\" not in data[\"country_groups\"][country_group_code]:\n",
    "\t\t\tdata[\"country_groups\"][country_group_code][\"subjects\"] = {}\n",
    "\t\tdata[\"country_groups\"][country_group_code][\"subjects\"][subject_code] = list(timeseries)\n",
    "\t\tif subject_code not in data[\"subjects\"]:\n",
    "\t\t\tdata[\"subjects\"][subject_code] = {}\n",
    "\t\t\tdata[\"subjects\"][subject_code][\"code\"] = subject_code\n",
    "\t\t\tdata[\"subjects\"][subject_code][\"descriptor\"] = subject_descriptor\n",
    "\t\t\tdata[\"subjects\"][subject_code][\"notes\"] = subject_notes\n",
    "\t\t\tdata[\"subjects\"][subject_code][\"units\"] = units\n",
    "\t\t\tdata[\"subjects\"][subject_code][\"scale\"] = scale\n",
    "\treturn data\n",
    "\n",
    "data = get_dict_from_df(df)\n",
    "data[\"current_year\"] = \"2023\" # we have to choose where the data ends and predictions start\n",
    "filepath_custom_query_country_groups_all_json = filepath_custom_query_country_groups_all.replace(\".csv\", \".json\")\n",
    "with open(filepath_custom_query_country_groups_all_json, \"w\") as f:\n",
    "\tjson.dump(data, f, indent=2) # 1.1 MB with indent=2, 500 KB without indent... doesn't matter much tbh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_subjects(data: dict):\n",
    "\t'''\n",
    "\t\tPrint a subject\n",
    "\t'''\n",
    "\tprint(f\"Subjects ({len(data['subjects'])}):\")\n",
    "\tfor subject_code, subject_data in data[\"subjects\"].items():\n",
    "\t\tprint(f\"{subject_code}: '{subject_data['descriptor']}'\")# ; units: '{subject_data['units']}' ; scale: '{subject_data['scale']}'\")\n",
    "\t\tprint(f\"    Units: '{subject_data['units']}'\")\n",
    "\t\tprint(f\"    Scale: '{subject_data['scale']}'\")\n",
    "\t\tprint(f\"    Notes: '{subject_data['notes']}'\")\n",
    "print_subjects(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_country_groups(data: dict):\n",
    "\t'''\n",
    "\t\tPrint a country group\n",
    "\t'''\n",
    "\tprint(f\"Country groups ({len(data['country_groups'])}):\")\n",
    "\tfor country_group_code, country_group_data in data[\"country_groups\"].items():\n",
    "\t\tprint(f\"{country_group_code}: '{country_group_data['name']}'\")\n",
    "\t\tprint(f\"    Subjects ({len(country_group_data['subjects'])}):\")\n",
    "\t\tfor subject_code, timeseries in country_group_data[\"subjects\"].items():\n",
    "\t\t\tprint(f\"        {subject_code}: {timeseries}\")\n",
    "\n",
    "# print_country_groups(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_country_groups_short(data: dict):\n",
    "\t'''\n",
    "\t\tPrint a country group\n",
    "\t'''\n",
    "\tprint(f\"Country groups ({len(data['country_groups'])}):\")\n",
    "\tfor country_group_code, country_group_data in data[\"country_groups\"].items():\n",
    "\t\tprint(f\"{country_group_code}: '{country_group_data['name']}'\")\n",
    "\n",
    "print_country_groups_short(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subjects_by_descriptor(data: dict, query: str) -> list[str]:\n",
    "\t'''\n",
    "\t\tFind subjects by descriptor\n",
    "\t'''\n",
    "\tsubject_codes = []\n",
    "\tfor subject_code, subject_data in data[\"subjects\"].items():\n",
    "\t\tif query.lower() in subject_data[\"descriptor\"].lower():\n",
    "\t\t\tsubject_codes.append(subject_code)\n",
    "\treturn subject_codes\n",
    "\n",
    "matches = find_subjects_by_descriptor(data, \"inflation\")\n",
    "print(f\"Found {len(matches)} matches:\")\n",
    "for match in matches:\n",
    "\tprint(f\"    {match}: '{data['subjects'][match]['descriptor']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print inflation values (code \"PCPIPCH\") for World (code \"001\") for the last 23 years (between \"current_year\" and \"current_year - 23\")\n",
    "index_current_year = data[\"years\"].index(data[\"current_year\"])\n",
    "n_years = 23\n",
    "index_current_minus_n = index_current_year - n_years\n",
    "values_inflation = data[\"country_groups\"][\"001\"][\"subjects\"][\"PCPIPCH\"][index_current_minus_n:index_current_year]\n",
    "print(f\"World inflation values for the last {n_years} years:\")\n",
    "years_list = data[\"years\"][index_current_minus_n:index_current_year]\n",
    "unit_inflation = data[\"subjects\"][\"PCPIPCH\"][\"units\"]\n",
    "# for i, value in enumerate(values):\n",
    "# \tprint(f\"    {data['years'][index_current_minus_n + i]}: {value}\")\n",
    "for year, value in zip(years_list, values_inflation):\n",
    "\tprint(f\"    {year}: {value} {unit_inflation.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create plots for analysis - for selected subject plot all country groups over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
