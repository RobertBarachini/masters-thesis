{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from typing import Optional\n",
    "\n",
    "# Project imports\n",
    "sys.path.append(os.getcwd())\n",
    "from src.py.analysis.yahoo.stocks.finance_df_utils import load_stock_csv, df_add_data, get_figure, filter_df_by_date, add_vline_annotation, save_fig, get_safe_filename, get_grouped_df\n",
    "from src.py.analysis.events import events\n",
    "# CPI\n",
    "import importlib\n",
    "sys.path.append(os.getcwd())\n",
    "cpi_adjust = importlib.import_module(\"src.py.scraping.world-bank.cpi_adjust\")\n",
    "cpi_adjust.initialize_cpi(date_cutoff=\"2018-08-01\", jagged=False) # jagged=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_index = \"data/scraped/yahoo/crypto/index.json\"\n",
    "path_csv_root = \"data/scraped/yahoo/crypto/csv\"\n",
    "path_output_root = \"data/analysis/yahoo/crypto\"\n",
    "\n",
    "if os.path.exists(path_output_root) is False:\n",
    "\tos.makedirs(path_output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index\n",
    "index = json.load(open(path_index, \"r\"))[\"urls\"] # type: list\n",
    "print(f\"Loaded index with {len(index)} crypto currency links\")\n",
    "print(\"\")\n",
    "print(f\"First entry: '{index[0]}'\")\n",
    "\n",
    "# Parse just the crypto symbol from url\n",
    "index = [x.split(\"/\")[-1].split(\"?\")[0] for x in index]\n",
    "print(f\"First entry (parsed): '{index[0]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all CSVs\n",
    "dfs_dict = {}\n",
    "dfs_fails = {}\n",
    "print(f\"Loading {len(index)} crypto CSVs.\")\n",
    "print(\"\")\n",
    "for i, symbol in enumerate(index):\n",
    "\tprint(f\"{i+1}/{len(index)} [{symbol}]                  \", end=\"\\r\")\n",
    "\ttry:\n",
    "\t\t# Load CSV\n",
    "\t\tdf = load_stock_csv(os.path.join(path_csv_root, f\"{symbol}.csv\"))\n",
    "\t\tfirst_date = str(df.index[0])\n",
    "\t\t# Check if data is within range (first date < 2018-10-01)\n",
    "\t\tif df.index[0] > datetime(2018, 8, 1):\n",
    "\t\t\traise Exception(\"Data starts after 2018-08-01.\")\n",
    "\t\t# Check if data is within range (last date > 2023-12-01)\n",
    "\t\tif df.index[-1] < datetime(2023, 12, 1):\n",
    "\t\t\traise Exception(\"Data ends before 2023-12-01.\")\n",
    "\t\t# Plotting interval is 2019-01-01 to 2023-12-26\n",
    "\t\t# start_date is set to 2018-10-01 to leave some for window\n",
    "\t\tdf = filter_df_by_date(df, start_date=\"2018-08-01\", end_date=\"2023-12-26\")\n",
    "\t\t# Adjust for CPI\n",
    "\t\t# df = cpi_adjust.adjust_for_inflation(df, \"USA\", columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"])\n",
    "\t\tdf = cpi_adjust.adjust_for_inflation(df, \"USA\", columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"])\n",
    "\t\t# Add to dict\n",
    "\t\tdfs_dict[symbol] = df\n",
    "\texcept Exception as e:\n",
    "\t\tif \"no such file or directory\" in str(e).lower():\n",
    "\t\t\te = \"No CSV file.\"\n",
    "\t\tdfs_fails[symbol] = str(e)\n",
    "\t# break # for testing (quicker iteration)\n",
    "print(\"\")\n",
    "print(f\"Loaded {len(dfs_dict)} crypto CSVs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bitcoin = dfs_dict[\"BTC-USD\"].copy()\n",
    "df_bitcoin = df_add_data(df_bitcoin)\n",
    "df_bitcoin = df_bitcoin.loc[\"2019-01-01\":]\n",
    "options = {\n",
    " \"w\": 1280,\n",
    " \"h\": 720,\n",
    " # \"traces\": [\"candlestick\"],\n",
    " \"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \"labels\": [\"Price ($)\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "fig = get_figure(df_bitcoin, title=\"Bitcoin (BTC-USD) price trend\", options=options)\n",
    "for event in events:\n",
    "\tevent_copy = event.copy()\n",
    "\tif \"offset\" in event_copy:\n",
    "\t\tdel event_copy[\"offset\"]\n",
    "\tif event_copy[\"group\"] == \"Crypto\":\n",
    "\t\tadd_vline_annotation(fig, event_copy)\n",
    "fig.show()\n",
    "\n",
    "output_path = os.path.join(path_output_root, \"bitcoin_price_trend_daily.png\")\n",
    "save_fig(fig, output_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bitcoin = dfs_dict[\"BTC-USD\"].copy()\n",
    "df_bitcoin = df_bitcoin.resample(\"W\").agg({\n",
    "\t    \"Open\": \"first\",\n",
    "\t    \"High\": \"max\",\n",
    "\t    \"Low\": \"min\",\n",
    "\t    \"Close\": \"last\",\n",
    "\t    \"Adj Close\": \"last\",\n",
    "\t    \"Volume\": \"sum\"\n",
    "\t})\n",
    "df_bitcoin = df_add_data(df_bitcoin)\n",
    "df_bitcoin = df_bitcoin.loc[\"2019-01-01\":]\n",
    "options = {\n",
    " \"w\": 1280,\n",
    " \"h\": 720,\n",
    " # \"traces\": [\"candlestick\"],\n",
    " \"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \"labels\": [\"Price ($)\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "fig = get_figure(df_bitcoin, title=\"Bitcoin (BTC-USD) price trend\", options=options)\n",
    "for event in events:\n",
    "\tevent_copy = event.copy()\n",
    "\tif \"offset\" in event_copy:\n",
    "\t\tdel event_copy[\"offset\"]\n",
    "\tif event_copy[\"group\"] == \"Crypto\":\n",
    "\t\tadd_vline_annotation(fig, event_copy)\n",
    "fig.show()\n",
    "\n",
    "output_path = os.path.join(path_output_root, \"bitcoin_price_trend_weekly.png\")\n",
    "save_fig(fig, output_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bitcoin = dfs_dict[\"BTC-USD\"].copy()\n",
    "df_bitcoin = df_add_data(df_bitcoin)\n",
    "columns = list(df_bitcoin.columns)\n",
    "df_bitcoin_temp = df_bitcoin.copy()\n",
    "df_bitcoin_temp = df_bitcoin_temp.resample(\"W\").agg({\n",
    "\t\"Open\": \"first\",\n",
    "\t\"High\": \"max\",\n",
    "\t\"Low\": \"min\",\n",
    "\t\"Close\": \"last\",\n",
    "\t\"Adj Close\": \"last\",\n",
    "\t\"Volume\": \"sum\"\n",
    "})\n",
    "df_bitcoin = df_bitcoin.resample(\"W\").mean()\n",
    "df_bitcoin[\"Open\"] = df_bitcoin_temp[\"Open\"]\n",
    "df_bitcoin[\"High\"] = df_bitcoin_temp[\"High\"]\n",
    "df_bitcoin[\"Low\"] = df_bitcoin_temp[\"Low\"]\n",
    "df_bitcoin[\"Close\"] = df_bitcoin_temp[\"Close\"]\n",
    "df_bitcoin[\"Adj Close\"] = df_bitcoin_temp[\"Adj Close\"]\n",
    "df_bitcoin[\"Volume\"] = df_bitcoin_temp[\"Volume\"]\n",
    "df_bitcoin = df_bitcoin.loc[\"2019-01-01\":]\n",
    "options = {\n",
    " \"w\": 1280,\n",
    " \"h\": 720,\n",
    " # \"traces\": [\"candlestick\"],\n",
    " \"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \"labels\": [\"Price ($)\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "fig = get_figure(df_bitcoin, title=\"Bitcoin (BTC-USD) price trend\", options=options)\n",
    "for event in events:\n",
    "\tevent_copy = event.copy()\n",
    "\tif \"offset\" in event_copy:\n",
    "\t\tdel event_copy[\"offset\"]\n",
    "\tif event_copy[\"group\"] == \"Crypto\":\n",
    "\t\tadd_vline_annotation(fig, event_copy)\n",
    "fig.show()\n",
    "\n",
    "output_path = os.path.join(path_output_root, \"bitcoin_price_trend_daily_then_weekly.png\")\n",
    "save_fig(fig, output_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print fails grouped and sorted by error\n",
    "print(f\"Failed to load {len(dfs_fails)} crypto CSVs.\")\n",
    "print(\"\")\n",
    "dfs_fails_grouped = { str(e): [] for e in set(dfs_fails.values()) }\n",
    "for ticker, e in dfs_fails.items():\n",
    "\tdfs_fails_grouped[str(e)].append(ticker)\n",
    "\n",
    "for e, tickers in sorted(dfs_fails_grouped.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "\tprint(f\"{len(tickers)} cryptos: {e}\")\n",
    "\tprint(f\"{', '.join(tickers[:10])}...\")\n",
    "\tprint(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print first 10 unique crypto symbols\n",
    "print(f\"First 10 crypto symbols:\")\n",
    "for i, symbol in enumerate(list(dfs_dict.keys())[:10]):\n",
    "\tprint(f\"{i+1:2d}: {symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Symbol column to start of each DataFrame\n",
    "for symbol, df in dfs_dict.items():\n",
    "\tif \"Symbol\" in df.columns: # ensure idempotence\n",
    "\t\tcontinue\n",
    "\tdf[\"Symbol\"] = symbol\n",
    "\tdf = df[[\"Symbol\"] + df.columns[:-1].tolist()]\n",
    "\tdfs_dict[symbol] = df\n",
    "\n",
    "dfs_dict[\"BTC-USD\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict[\"BTC-USD\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Volume_value column by multiplying Volume by Close\n",
    "def add_volume_value(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\tdf[\"Volume_value\"] = df[\"Volume\"] * df[\"Close\"]\n",
    "\treturn df\n",
    "\n",
    "df_volume_value = add_volume_value(dfs_dict[\"BTC-USD\"])\n",
    "df_volume_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Open_I, High_I, Low_I, Close_I, Adj_Close_I, Volume_I columns using a specified date as I = 100\n",
    "def add_index_values(df: pd.DataFrame, date: str) -> pd.DataFrame:\n",
    "\tindex_value = df.loc[date, \"Open\"]\n",
    "\tdf[\"Open_I\"] = df[\"Open\"] / index_value * 100  # type: ignore\n",
    "\tindex_value = df.loc[date, \"High\"]\n",
    "\tdf[\"High_I\"] = df[\"High\"] / index_value * 100  # type: ignore\n",
    "\tindex_value = df.loc[date, \"Low\"]\n",
    "\tdf[\"Low_I\"] = df[\"Low\"] / index_value * 100  # type: ignore\n",
    "\tindex_value = df.loc[date, \"Close\"]\n",
    "\tdf[\"Close_I\"] = df[\"Close\"] / index_value * 100  # type: ignore\n",
    "\tindex_value = df.loc[date, \"Adj Close\"]\n",
    "\tdf[\"Adj_Close_I\"] = df[\"Adj Close\"] / index_value * 100  # type: ignore\n",
    "\t# index_value = df.loc[date, \"Volume\"]\n",
    "\t# df[\"Volume_I\"] = df[\"Volume\"] / index_value * 100  # type: ignore\n",
    "\t# NOTE: this approach can scramble the the values because of relative scaling\n",
    "\t# \t\t  as a consequence, the values like High_I can be lower than Low_I\n",
    "\t# # Invert the values where High < Low\n",
    "\t# df[\"temp\"] = df[\"High_I\"]\n",
    "\t# df.loc[df[\"High_I\"] < df[\"Low_I\"],\n",
    "\t#        \"High_I\"] = df.loc[df[\"High_I\"] < df[\"Low_I\"], \"Low_I\"]\n",
    "\t# df.loc[df[\"High_I\"] < df[\"Low_I\"],\n",
    "\t#        \"Low_I\"] = df.loc[df[\"High_I\"] < df[\"Low_I\"], \"temp\"]\n",
    "\t# # Switch the Close_I, Open_I for all rows where their order is different from Close, Open\n",
    "\t# rows_og = df[\"Close\"] < df[\"Open\"]\n",
    "\t# rows_i = df[\"Close_I\"] < df[\"Open_I\"]\n",
    "\t# mask = rows_og != rows_i\n",
    "\t# count_pre = mask.sum()\n",
    "\t# df.loc[mask, \"temp\"] = df.loc[mask, \"Close_I\"]\n",
    "\t# df.loc[mask, \"Close_I\"] = df.loc[mask, \"Open_I\"]\n",
    "\t# df.loc[mask, \"Open_I\"] = df.loc[mask, \"temp\"]\n",
    "\t# rows_og = df[\"Close\"] < df[\"Open\"]\n",
    "\t# rows_i = df[\"Close_I\"] < df[\"Open_I\"]\n",
    "\t# mask = rows_og != rows_i\n",
    "\t# count_post = mask.sum()\n",
    "\t# # Drop temp column\n",
    "\t# df.drop(columns=[\"temp\"], inplace=True)\n",
    "\t# NOTE: a more complete approach would be to scale Open_I, High_I, and Low_I proportionally to Open, High, and Low using Close_I as a base\n",
    "\t#       calculated from the relative scaling of Close_I and Close - each daily measurement / candle should retain the same proportions and order\n",
    "\treturn df\n",
    "\n",
    "# 2019-01-01 = 100\n",
    "df_scaled = add_index_values(dfs_dict[\"BTC-USD\"], \"2019-01-01\")\n",
    "# df_scaled.head()\n",
    "# show df from 2019-01-01 to 2019-01-05\n",
    "df_scaled.loc[\"2019-01-01\":\"2019-01-05\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Bitcoin's Close data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all DataFrames to add index values\n",
    "for symbol, df in dfs_dict.items():\n",
    "\tdf = add_index_values(df, \"2019-01-01\")\n",
    "\tdfs_dict[symbol] = df\n",
    "\n",
    "df_scaled = dfs_dict[\"BTC-USD\"]\n",
    "df_scaled.loc[\"2019-01-01\":\"2019-01-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot first 5 crypto symbols on the same plot\n",
    "# fig = px.line()\n",
    "# for symbol, df in list(dfs_dict.items())[:5]:\n",
    "# \t# fig.add_trace(go.Scatter(x=df.index, y=df[\"Close\"], name=symbol))\n",
    "# \tfig.add_trace(go.Scatter(x=df.index, y=df[\"Close_I\"], name=symbol))\n",
    "# fig.update_layout(title=\"First 5 crypto symbols\")\n",
    "# fig.show()\n",
    "\n",
    "# Make 2 subplots\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02)\n",
    "\n",
    "# Plot first 5 crypto symbols - Close on top plot and Close_I on bottom plot\n",
    "# use the same color for each symbol in both plots\n",
    "for i, (symbol, df) in enumerate(list(dfs_dict.items())[:5]):\n",
    "\t# fig.add_trace(go.Scatter(x=df.index, y=df[\"Close\"], name=symbol), row=1, col=1)\n",
    "\t# fig.add_trace(go.Scatter(x=df.index, y=df[\"Close_I\"], name=symbol), row=2, col=1)\n",
    "\tcolor = px.colors.qualitative.Plotly[i]\n",
    "\tfig.add_trace(go.Scatter(x=df.index, y=df[\"Close\"], name=f\"{symbol} Close\", line=dict(color=color)), row=1, col=1)\n",
    "\tfig.add_trace(go.Scatter(x=df.index, y=df[\"Close_I\"], name=f\"{symbol} Close_I\", line=dict(color=color)), row=2, col=1)\n",
    "# add axes labels\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Close\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Close_I\", row=2, col=1)\n",
    "fig.update_layout(title=\"Currency prices versus index values for the first 5 crypto symbols (2019-01-01 = 100)\")\n",
    "fig.update_layout(width=1000, height=400)\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=40, pad=0))\n",
    "fig.show()\n",
    "\n",
    "# Save the figure\n",
    "path_fig = os.path.join(path_output_root, \"crypto-close-vs-close-i-first-5.png\")\n",
    "# 2x zoom\n",
    "save_fig(fig, path_fig, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE: move to utils\n",
    "\n",
    "# events = []\n",
    "\n",
    "# # COVID-19 market crash\n",
    "# events.append({\n",
    "# \t\"date\": datetime(2020, 2, 20),\n",
    "# \t\"annotation\": \"MC\",\n",
    "# \t\"description\": \"COVID-19 market crash\"\n",
    "# })\n",
    "\n",
    "# # COVID-19 market crash end\n",
    "# events.append({\n",
    "# \t\"date\": datetime(2020, 4, 7),\n",
    "# \t\"annotation\": \"MC end\",\n",
    "# \t\"description\": \"COVID-19 market crash end\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_candles(df: pd.DataFrame) -> pd.DataFrame:\n",
    "# \t# Rules:\n",
    "# \t# 1. Low <= (Open <= Close || Open >= Close) <= High\n",
    "\n",
    "# \t# Process:\n",
    "# \t# set the lo\n",
    "\n",
    "# \t# Old attempt (incomplete)\n",
    "# \tdf_n[\"temp\"] = df_n[\"High\"]\n",
    "# \tdf_n.loc[df_n[\"High\"] < df_n[\"Low\"],\n",
    "# \t       \"High\"] = df_n.loc[df_n[\"High\"] < df_n[\"Low\"], \"Low\"]\n",
    "# \tdf_n.loc[df_n[\"High\"] < df_n[\"Low\"],\n",
    "# \t       \"Low\"] = df_n.loc[df_n[\"High\"] < df_n[\"Low\"], \"temp\"]\n",
    "# \t# Switch the Close, Open for all rows where their order is different from Close, Open\n",
    "# \trows_og = df_n[\"Close\"] < df_n[\"Open\"]\n",
    "# \trows = df_n[\"Close\"] < df_n[\"Open\"]\n",
    "# \tmask = rows_og != rows\n",
    "# \tcount_pre = mask.sum()\n",
    "# \tdf_n.loc[mask, \"temp\"] = df_n.loc[mask, \"Close\"]\n",
    "# \tdf_n.loc[mask, \"Close\"] = df_n.loc[mask, \"Open\"]\n",
    "# \tdf_n.loc[mask, \"Open\"] = df_n.loc[mask, \"temp\"]\n",
    "# \trows_og = df_n[\"Close\"] < df_n[\"Open\"]\n",
    "# \trows = df_n[\"Close\"] < df_n[\"Open\"]\n",
    "# \tmask = rows_og != rows\n",
    "# \tcount_post = mask.sum()\n",
    "# \t# Drop temp column\n",
    "# \tdf_n.drop(columns=[\"temp\"], inplace=True)\n",
    "\n",
    "# def get_grouped_fig(dfs_dict: dict,\n",
    "#                     symbols: list,\n",
    "#                     title: str,\n",
    "#                     events: list,\n",
    "#                     options: Optional[dict] = None) -> go.Figure:\n",
    "# \tdfs_dict_filtered = {symbol: dfs_dict[symbol] for symbol in symbols}\n",
    "# \tdf_n = pd.concat(dfs_dict_filtered.copy().values())\n",
    "# \t# df_n = df_n.copy()\n",
    "# \tdf_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "# \t# resample to weekly\n",
    "# \tdf_n = df_n.resample(\"W\").mean()\n",
    "# \t# df_n = df_n.resample(\"W\").agg({\n",
    "# \t# \t\"Open\": \"mean\",\n",
    "# \t# \t\"High\": \"mean\",\n",
    "# \t# \t\"Low\": \"mean\",\n",
    "# \t# \t\"Close\": \"mean\",\n",
    "# \t# \t\"Adj Close\": \"mean\",\n",
    "# \t# \t\"Volume\": \"sum\",\n",
    "# \t# })\n",
    "# \t# df_n = df_n.resample(\"W\").agg({\n",
    "# \t# \t\"Open\": \"first\",\n",
    "# \t# \t\"High\": \"max\",\n",
    "# \t# \t\"Low\": \"min\",\n",
    "# \t# \t\"Close\": \"last\",\n",
    "# \t# \t\"Adj Close\": \"last\",\n",
    "# \t# \t\"Volume\": \"sum\",\n",
    "# \t# })\n",
    "# \t# df_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\n",
    "# \tfig = get_figure(df_n, title, options)\n",
    "# \tfor event in events:\n",
    "# \t\tadd_vline_annotation(fig, event, textangle=-20)\n",
    "# \treturn fig\n",
    "\n",
    "def get_grouped_fig_alt(dfs_dict: dict,\n",
    "                    symbols: list,\n",
    "                    title: str,\n",
    "                    events: list,\n",
    "                    options: Optional[dict] = None) -> go.Figure:\n",
    "\tdfs_dict_filtered = {symbol: dfs_dict[symbol] for symbol in symbols}\n",
    "\tdf_n = pd.concat(dfs_dict_filtered.values())\n",
    "\tdf_n = df_n.copy()\n",
    "\t# df_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\t# resample to weekly\n",
    "\tdf_n = df_n.resample(\"W\").agg({\n",
    "\t\t\"Open\": \"mean\",\n",
    "\t\t\"High\": \"mean\",\n",
    "\t\t\"Low\": \"mean\",\n",
    "\t\t\"Close\": \"mean\",\n",
    "\t\t\"Adj Close\": \"mean\",\n",
    "\t\t\"Volume\": \"sum\",\n",
    "\t})\n",
    "\t# df_n = df_n.resample(\"W\").agg({\n",
    "\t# \t\"Open\": \"first\",\n",
    "\t# \t\"High\": \"max\",\n",
    "\t# \t\"Low\": \"min\",\n",
    "\t# \t\"Close\": \"last\",\n",
    "\t# \t\"Adj Close\": \"last\",\n",
    "\t# \t\"Volume\": \"sum\",\n",
    "\t# })\n",
    "\tdf_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\n",
    "\tfig = get_figure(df_n, title, options)\n",
    "\tfor event in events:\n",
    "\t\tadd_vline_annotation(fig, event, textangle=-20)\n",
    "\treturn fig\n",
    "\n",
    "\n",
    "def get_grouped_fig(dfs_dict: dict,\n",
    "                    symbols: list,\n",
    "                    title: str,\n",
    "                    events: list,\n",
    "                    options: Optional[dict] = None) -> go.Figure:\n",
    "\tdfs_dict_filtered = {symbol: dfs_dict[symbol] for symbol in symbols}\n",
    "\tdf_n = pd.concat(dfs_dict_filtered.copy().values())\n",
    "\t# df_n = df_n.copy()\n",
    "\tdf_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\t# resample to weekly\n",
    "\tvolume = df_n[\"Volume\"].resample(\"W\").sum()\n",
    "\tvolume_sma = df_n[\"SMA_volume\"].resample(\"W\").sum()\n",
    "\tdf_n = df_n.resample(\"W\").mean()\n",
    "\tdf_n[\"Volume\"] = volume\n",
    "\tdf_n[\"SMA_volume\"] = volume_sma\n",
    "\t# df_n = df_n.resample(\"W\").agg({\n",
    "\t# \t\"Open\": \"mean\",\n",
    "\t# \t\"High\": \"mean\",\n",
    "\t# \t\"Low\": \"mean\",\n",
    "\t# \t\"Close\": \"mean\",\n",
    "\t# \t\"Adj Close\": \"mean\",\n",
    "\t# \t\"Volume\": \"sum\",\n",
    "\t# })\n",
    "\t# df_n = df_n.resample(\"W\").agg({\n",
    "\t# \t\"Open\": \"first\",\n",
    "\t# \t\"High\": \"max\",\n",
    "\t# \t\"Low\": \"min\",\n",
    "\t# \t\"Close\": \"last\",\n",
    "\t# \t\"Adj Close\": \"last\",\n",
    "\t# \t\"Volume\": \"sum\",\n",
    "\t# })\n",
    "\t# df_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\tfig = get_figure(df_n, title, options)\n",
    "\tfor event in events:\n",
    "\t\tadd_vline_annotation(fig, event, textangle=-20)\n",
    "\treturn fig\n",
    "\n",
    "# def get_grouped_fig(dfs_dict: dict,\n",
    "#                     symbols: list,\n",
    "#                     title: str,\n",
    "#                     events: list,\n",
    "#                     options: Optional[dict] = None) -> go.Figure:\n",
    "# \tdfs_dict_filtered = {symbol: dfs_dict[symbol] for symbol in symbols}\n",
    "# \tdf_n = pd.concat(dfs_dict_filtered.copy().values())\n",
    "# \t# df_n = df_n.copy()\n",
    "\t\n",
    "# \tdf_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\t\n",
    "# \t# resample to weekly\n",
    "# \tvolume = df_n[\"Volume\"].resample(\"W\").sum()\n",
    "# \tvolume_sma = df_n[\"SMA_volume\"].resample(\"W\").sum()\n",
    "# \tdf_n = df_n.resample(\"W\").mean()\n",
    "# \tdf_n[\"Volume\"] = volume\n",
    "# \tdf_n[\"SMA_volume\"] = volume_sma\n",
    "\t\n",
    "# \t# df_n = df_n.resample(\"W\").agg({\n",
    "# \t# \t\"Open\": \"mean\",\n",
    "# \t# \t\"High\": \"mean\",\n",
    "# \t# \t\"Low\": \"mean\",\n",
    "# \t# \t\"Close\": \"mean\",\n",
    "# \t# \t\"Adj Close\": \"mean\",\n",
    "# \t# \t\"Volume\": \"sum\",\n",
    "# \t# })\n",
    "# \t# df_n = df_n.resample(\"W\").agg({\n",
    "# \t# \t\"Open\": \"first\",\n",
    "# \t# \t\"High\": \"max\",\n",
    "# \t# \t\"Low\": \"min\",\n",
    "# \t# \t\"Close\": \"last\",\n",
    "# \t# \t\"Adj Close\": \"last\",\n",
    "# \t# \t\"Volume\": \"sum\",\n",
    "# \t# })\n",
    "# \t# df_n = get_grouped_df(df_n, start_date=\"2019-01-01\")\n",
    "\n",
    "# \tfig = get_figure(df_n, title, options)\n",
    "# \t# for event in events:\n",
    "# \t# \tadd_vline_annotation(fig, event, textangle=-20)\n",
    "# \treturn fig\n",
    "\n",
    "# # Example with just first entry (BTC-USD)\n",
    "btc_symbol = list(dfs_dict.keys())[0]\n",
    "options = {\n",
    " \"w\": 1280,\n",
    " \"h\": 720,\n",
    " # \"traces\": [\"candlestick\"],\n",
    " \"traces\": [],\n",
    " \"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \"labels\": [\"Price ($)\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "fig = get_grouped_fig(dfs_dict, [btc_symbol], f\"Bitcoin ({btc_symbol}) price trend\", events, options)\n",
    "fig.show()\n",
    "\n",
    "# # Just single plot\n",
    "# btc_df = dfs_dict[\"BTC-USD\"].copy()\n",
    "# btc_df = btc_df.resample(\"W\").agg({\n",
    "# \t\t\"Open\": \"first\",\n",
    "# \t\t\"High\": \"max\",\n",
    "# \t\t\"Low\": \"min\",\n",
    "# \t\t\"Close\": \"last\",\n",
    "# \t\t\"Adj Close\": \"last\",\n",
    "# \t\t\"Volume\": \"sum\",\n",
    "# \t})\n",
    "# btc_df = get_grouped_df(btc_df, start_date=\"2019-01-01\")\n",
    "# fig = get_figure(btc_df, f\"Bitcoin ({btc_symbol}) price trend\", options)\n",
    "# for event in events:\n",
    "# \tadd_vline_annotation(fig, event, textangle=-20)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "# Save the figure\n",
    "path_fig = os.path.join(path_output_root, f\"bitcoin-price-trend.png\")\n",
    "save_fig(fig, path_fig, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace column values of Open with Open_I, High with High_I, Low with Low_I, Close with Close_I, Adj Close with Adj_Close_I, Volume with Volume_I\n",
    "for symbol, df in dfs_dict.items():\n",
    "\tif \"Open_I\" in df.columns:\n",
    "\t\t# drop original columns\n",
    "\t\tdf = df.drop(\n",
    "\t\t    columns=[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\"])#, \"Volume\"])\n",
    "\t\t# rename columns\n",
    "\t\tdf = df.rename(\n",
    "\t\t    columns={\n",
    "\t\t        \"Open_I\": \"Open\",\n",
    "\t\t        \"High_I\": \"High\",\n",
    "\t\t        \"Low_I\": \"Low\",\n",
    "\t\t        \"Close_I\": \"Close\",\n",
    "\t\t        \"Adj_Close_I\": \"Adj Close\",\n",
    "\t\t        # \"Volume_I\": \"Volume\"\n",
    "\t\t    })\n",
    "\tdfs_dict[symbol] = df\n",
    "\n",
    "# show btc from 2019-01-01 to 2019-01-05\n",
    "dfs_dict[\"BTC-USD\"].loc[\"2019-01-01\":\"2019-01-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Impute extreme values (using a rolling window) by replacing them with the mean of the window\n",
    "# def impute_extreme_values(df: pd.DataFrame, window: int) -> pd.DataFrame:\n",
    "# \tdf[\"Open\"] = df[\"Open\"].rolling(window=window, min_periods=1).mean()\n",
    "# \tdf[\"High\"] = df[\"High\"].rolling(window=window, min_periods=1).mean()\n",
    "# \tdf[\"Low\"] = df[\"Low\"].rolling(window=window, min_periods=1).mean()\n",
    "# \tdf[\"Close\"] = df[\"Close\"].rolling(window=window, min_periods=1).mean()\n",
    "# \tdf[\"Adj Close\"] = df[\"Adj Close\"].rolling(window=window, min_periods=1).mean()\n",
    "# \tdf[\"Volume\"] = df[\"Volume\"].rolling(window=window, min_periods=1).mean()\n",
    "# \treturn df\n",
    "\n",
    "# for symbol, df in dfs_dict.items():\n",
    "# \tdf = impute_extreme_values(df, 7)\n",
    "# \tdfs_dict[symbol] = df\n",
    "# dfs_dict[\"BTC-USD\"].loc[\"2019-01-01\":\"2019-01-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_moving(arr: np.ndarray,\n",
    "                           window_size: int = 7,\n",
    "                           threshold: float = 3) -> np.ndarray:\n",
    "\tarr = arr.astype(float)\n",
    "\t# if arr is [1,2,3,4,5] and window size is 2, then windows arr is [[1,2], [3,4], [5]]\n",
    "\tremainder = len(arr) % window_size\n",
    "\tarr, remainder_arr = arr[:-remainder], arr[-remainder:]\n",
    "\tnum_subarrays = int(len(arr) / window_size)\n",
    "\twindows = np.array_split(arr, num_subarrays)\n",
    "\t# add window_size - remainder elements from the end of the last subarray to the remainder_arr to make windows homogeneous\n",
    "\tmissing = window_size - remainder\n",
    "\tif missing > 0:\n",
    "\t\tremainder_arr = np.append(windows[-1][-missing:], remainder_arr)\n",
    "\twindows.append(remainder_arr)\n",
    "\twindows = np.array(windows)\n",
    "\t# means = np.mean(windows, axis=1)\n",
    "\tfor window in windows:  # alternatively calculate odd one out for each window\n",
    "\t\t# # detect outliers\n",
    "\t\t# mean = np.median(window)  # np.mean(window)\n",
    "\t\t# std = np.std(window)\n",
    "\t\t# outliers = np.array(np.abs(window - mean) > threshold * std)\n",
    "\t\t# detect outliers - alternative method\n",
    "\t\tmedian = np.median(window)\n",
    "\t\tiqr = np.percentile(window, 75) - np.percentile(window, 25)\n",
    "\t\toutliers = np.array(np.abs(window - median) > threshold * iqr)\n",
    "\t\t# calculate mean without outliers\n",
    "\t\t# window_no_outliers = window[outliers == False]\n",
    "\t\twindow_no_outliers = window[~outliers]\n",
    "\t\tif len(window_no_outliers) == 0 or len(window_no_outliers) == len(window):\n",
    "\t\t\tcontinue\n",
    "\t\tmean_no_outliers = np.mean(window_no_outliers)\n",
    "\t\twindow[outliers] = mean_no_outliers\n",
    "\t# flatten windows\n",
    "\tarr_no_outliers = np.concatenate(windows)\n",
    "\tif missing > 0:\n",
    "\t\tarr_no_outliers, remainder_arr = arr_no_outliers[:\n",
    "\t\t                                                 -window_size], arr_no_outliers[\n",
    "\t\t                                                     -window_size:]\n",
    "\t\tarr_no_outliers = np.append(arr_no_outliers, remainder_arr[-missing:])\n",
    "\treturn arr_no_outliers\n",
    "\ta = 0\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5, 50, 7, 8, 9, 10])\n",
    "window = 4\n",
    "threshold = 3\n",
    "print(list(arr))\n",
    "arr = remove_outliers_moving(arr, window, threshold)\n",
    "print(list(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove outliers from all DataFrames\n",
    "# for i, (symbol, df) in enumerate(dfs_dict.items()):\n",
    "# \tprint(f\"{i+1}/{len(dfs_dict)} [{symbol}]                  \", end=\"\\r\")\n",
    "# \t# processed = remove_outliers_moving(df[\"Close\"].values,\n",
    "# \t#                                    window_size=7,\n",
    "# \t#                                    threshold=3)\n",
    "# \t# df[\"Close\"] = processed\n",
    "# \tfor col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]:\n",
    "# \t\tprocessed = remove_outliers_moving(df[col].values, window_size=7, threshold=3)\n",
    "# \t\tdf[col] = processed\n",
    "# \tdfs_dict[symbol] = df\n",
    "# print(\"\")\n",
    "\n",
    "# # show btc from 2019-01-01 to 2019-01-05\n",
    "# dfs_dict[\"BTC-USD\"].loc[\"2019-01-01\":\"2019-01-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WORKS WAY QUICKER\n",
    "\n",
    "# Impute outliers from all DataFrames using z-score with\n",
    "z_threshold = 20 #3 # - set depending on specific data\n",
    "for i, (symbol, df) in enumerate(dfs_dict.items()):\n",
    "\tprint(f\"{i+1}/{len(dfs_dict)} [{symbol}]                  \", end=\"\\r\")\n",
    "\tfor col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]:\n",
    "\t\tz = np.abs(stats.zscore(df[col]))\n",
    "\t\t# directly set outliers to NaN\n",
    "\t\tmask = np.array(z > z_threshold)\n",
    "\t\t# df[col][mask] = np.nan # this produces warnings \"A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "\t\tdf.loc[mask, col] = np.nan\n",
    "\t\t# outliers = np.where(z > z_threshold)\n",
    "\t\t# outliers = df[col][z > z_threshold]\n",
    "\t\t# if len(outliers[0]) > 0:\n",
    "\t\t# \ta = 0\n",
    "\t\t# df = df[(z < z_threshold)]\n",
    "\t\t# replace outliers with NaN\n",
    "\t\t# df[col].iloc[outliers] = np.nan\n",
    "\t\t# linear interpolation to fill NaN\n",
    "\t\tdf[col] = df[col].interpolate()\n",
    "\tdfs_dict[symbol] = df\n",
    "\n",
    "print(\"\")\n",
    "# show btc from 2019-01-01 to 2019-01-05\n",
    "dfs_dict[\"BTC-USD\"].loc[\"2019-01-01\":\"2019-01-05\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first n symbols\n",
    "n = 10000  # 10000 # set some big number to get all\n",
    "n = 1000 # CLT - Central Limit Theorem minimum number of samples\n",
    "n = min(n, len(dfs_dict)) # ensure n is not bigger than number of symbols\n",
    "# symbols = list(dfs_dict.keys())[:n]  # first n\n",
    "# symbols = random.sample(list(dfs_dict.keys()), n) # random n\n",
    "sampling_type = \"first\"  # \"random\" or \"first\"\n",
    "if sampling_type == \"random\":\n",
    "\tsymbols = random.sample(list(dfs_dict.keys()), n)  # random n\n",
    "elif sampling_type == \"first\":\n",
    "\tsymbols = list(dfs_dict.keys())[:n]  # first n\n",
    "else:\n",
    "\traise ValueError(\"Invalid sampling_type\")\n",
    "print(f\"Selected {len(symbols)} random symbols:\")\n",
    "for i, symbol in enumerate(symbols):\n",
    "\tprint(f\"{symbol.replace('-USD', '')}, \", end=\"\")\n",
    "\tif i > 10:\n",
    "\t\tprint(\"\")\n",
    "\t\tprint(\"...\")\n",
    "\t\tbreak\n",
    "print(\"\")\n",
    "options = {\n",
    " \t\"w\": 1280,\n",
    " \t\"h\": 720,\n",
    "#  \"traces\": [\"candlestick\"],\n",
    " \t\"traces\": [],\n",
    "\t\"color_changes\": False,\n",
    " \t\"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \t\"labels\": [\"Index values\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "# fig = get_grouped_fig(dfs_dict.copy(), symbols, f\"Market trends for {sampling_type} {n}/{len(dfs_dict)} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig = get_grouped_fig_alt(dfs_dict.copy(), symbols, f\"Market trend for {sampling_type} {n} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig.show()\n",
    "\n",
    "# Save figure\n",
    "filename = f\"crypto-market-trends-{sampling_type}-{len(symbols)}-weekly\"\n",
    "path_output = os.path.join(path_output_root, f\"{filename}.png\")\n",
    "save_fig(fig, path_output, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first n symbols\n",
    "n = 10000  # 10000 # set some big number to get all\n",
    "n = 1000 # CLT - Central Limit Theorem minimum number of samples\n",
    "n = min(n, len(dfs_dict)) # ensure n is not bigger than number of symbols\n",
    "# symbols = list(dfs_dict.keys())[:n]  # first n\n",
    "# symbols = random.sample(list(dfs_dict.keys()), n) # random n\n",
    "sampling_type = \"first\"  # \"random\" or \"first\"\n",
    "if sampling_type == \"random\":\n",
    "\tsymbols = random.sample(list(dfs_dict.keys()), n)  # random n\n",
    "elif sampling_type == \"first\":\n",
    "\tsymbols = list(dfs_dict.keys())[:n]  # first n\n",
    "else:\n",
    "\traise ValueError(\"Invalid sampling_type\")\n",
    "print(f\"Selected {len(symbols)} random symbols:\")\n",
    "for i, symbol in enumerate(symbols):\n",
    "\tprint(f\"{symbol.replace('-USD', '')}, \", end=\"\")\n",
    "\tif i > 10:\n",
    "\t\tprint(\"\")\n",
    "\t\tprint(\"...\")\n",
    "\t\tbreak\n",
    "print(\"\")\n",
    "options = {\n",
    " \t\"w\": 1280,\n",
    " \t\"h\": 720,\n",
    "#  \"traces\": [\"candlestick\"],\n",
    " \t\"traces\": [],\n",
    "\t\"color_changes\": False,\n",
    " \t\"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \t\"labels\": [\"Index values\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "# fig = get_grouped_fig(dfs_dict.copy(), symbols, f\"Market trends for {sampling_type} {n}/{len(dfs_dict)} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig = get_grouped_fig(dfs_dict.copy(), symbols, f\"Market trend for {sampling_type} {n} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig.show()\n",
    "\n",
    "# Save figure\n",
    "filename = f\"crypto-market-trends-{sampling_type}-{len(symbols)}-daily\"\n",
    "path_output = os.path.join(path_output_root, f\"{filename}.png\")\n",
    "save_fig(fig, path_output, scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first n symbols\n",
    "n = 10000  # 10000 # set some big number to get all\n",
    "n = 30 # CLT - Central Limit Theorem minimum number of samples\n",
    "n = min(n, len(dfs_dict)) # ensure n is not bigger than number of symbols\n",
    "# symbols = list(dfs_dict.keys())[:n]  # first n\n",
    "# symbols = random.sample(list(dfs_dict.keys()), n) # random n\n",
    "sampling_type = \"random\"  # \"random\" or \"first\"\n",
    "if sampling_type == \"random\":\n",
    "\tsymbols = random.sample(list(dfs_dict.keys()), n)  # random n\n",
    "elif sampling_type == \"first\":\n",
    "\tsymbols = list(dfs_dict.keys())[:n]  # first n\n",
    "else:\n",
    "\traise ValueError(\"Invalid sampling_type\")\n",
    "print(f\"Selected {len(symbols)} random symbols:\")\n",
    "for i, symbol in enumerate(symbols):\n",
    "\tprint(f\"{symbol.replace('-USD', '')}, \", end=\"\")\n",
    "\tif i > 10:\n",
    "\t\tprint(\"\")\n",
    "\t\tprint(\"...\")\n",
    "\t\tbreak\n",
    "print(\"\")\n",
    "options = {\n",
    " \t\"w\": 1280,\n",
    " \t\"h\": 720,\n",
    "#  \"traces\": [\"candlestick\"],\n",
    " \t\"traces\": [],\n",
    "\t\"color_changes\": False,\n",
    " \t\"margin\": {\"r\": 0, \"t\": 60, \"b\": 0, \"l\": 0},\n",
    " \t\"labels\": [\"Index values\", \"Volume\", \"MACD\"],\n",
    "}\n",
    "# fig = get_grouped_fig(dfs_dict.copy(), symbols, f\"Market trends for {sampling_type} {n}/{len(dfs_dict)} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig = get_grouped_fig(dfs_dict.copy(), symbols, f\"Market trend for {sampling_type} {n} cryptocurrencies | 2019-01-01 = 100\", events, options)\n",
    "fig.show()\n",
    "\n",
    "# Save figure\n",
    "filename = f\"crypto-market-trends-{sampling_type}-{len(symbols)}-daily\"\n",
    "path_output = os.path.join(path_output_root, f\"{filename}.png\")\n",
    "save_fig(fig, path_output, scale=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
