{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "# Project imports\n",
    "sys.path.append(os.getcwd())\n",
    "from src.py.utils.trash import move_to_trash, get_trash_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_output_root = \"data/keepa/products/domains\"\n",
    "# domain_id: Amazon domain ID - Valid values: [ 1: com | 2: co.uk 231 | 3: de | 4: fr | 5: co.jp | 6: ca | 8: it | 9: es | 10: in | 11: com.mx ]\n",
    "domains_map = {\n",
    "\t\"1\": \"com\",\n",
    "\t\"2\": \"co.uk\",\n",
    "\t\"3\": \"de\",\n",
    "\t\"4\": \"fr\",\n",
    "\t\"5\": \"co.jp\",\n",
    "\t\"6\": \"ca\",\n",
    "\t\"8\": \"it\",\n",
    "\t\"9\": \"es\",\n",
    "\t\"10\": \"in\",\n",
    "\t\"11\": \"com.mx\",\n",
    "}\n",
    "domains = sorted(os.listdir(path_output_root)) # type: ignore\n",
    "domains = {domain: {\"path\": os.path.join(path_output_root, domain)}for domain in domains} # type: dict\n",
    "path_parsed_products = \"data/scraped/camel/parsed-products.json\"\n",
    "\n",
    "print(f\"Domains: {json.dumps(domains, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_json_files(path: str) -> dict:\n",
    "\tjson_files = {}\n",
    "\tfor root, dirs, files in os.walk(path):\n",
    "\t\tfor file in files:\n",
    "\t\t\tif file.endswith(\".json\"):\n",
    "\t\t\t\tjson_files[file.split(\".\")[0]] = os.path.join(root, file)\n",
    "\treturn json_files\n",
    "\n",
    "for domain in domains:\n",
    "\tdomains[domain][\"json_files\"] = get_all_json_files(domains[domain][\"path\"])\n",
    "\tprint(f\"Domain {domain} got {len(domains[domain]['json_files'])} json files\")\n",
    "\n",
    "print(\"\")\n",
    "print(f\"First json_files key value pair of domain 1: {list(domains['1']['json_files'].items())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failed_files(json_files: dict) -> dict:\n",
    "\tfailed_files = {}\n",
    "\tfor i, (asin, filepath) in enumerate(json_files.items()):\n",
    "\t\tprint(f\"Checking file {i+1}/{len(json_files)}: {asin}             \", end=\"\\r\")\n",
    "\t\ttry:\n",
    "\t\t\twith open(filepath) as f:\n",
    "\t\t\t\tdata = json.load(f)\n",
    "\t\t\t\tif \"error\" in data:\n",
    "\t\t\t\t\tfailed_files[asin] = data[\"error\"]\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tfailed_files[asin] = f\"File parsing error: {e}\"\n",
    "\treturn failed_files\n",
    "\n",
    "for i, domain_id in enumerate(domains.keys()):\n",
    "\tprint(f\"Checking domain {i+1}/{len(domains)}: amazon.{domains_map[domain_id]}\")\n",
    "\tdomains[domain_id][\"failed_files\"] = get_failed_files(domains[domain_id][\"json_files\"])\n",
    "\tprint(\"\")\n",
    "\tprint(f\"Domain amazon.{domains_map[domain_id]} got {len(domains[domain_id]['failed_files'])} failed files\")\n",
    "\tprint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove failed files from the json_files dict for each domain\n",
    "\n",
    "for domain in domains:\n",
    "\tfor asin in domains[domain][\"failed_files\"]:\n",
    "\t\tfor domain_del in domains:\n",
    "\t\t\tif asin in domains[domain_del][\"json_files\"]:\n",
    "\t\t\t\tdel domains[domain_del][\"json_files\"][asin]\n",
    "\n",
    "\n",
    "# Print count of asins for each domain\n",
    "for domain_id, domain in domains.items():\n",
    "\tprint(f\"Domain amazon.{domains_map[domain_id]} has {len(domain['json_files'])} asins remaining\")\n",
    "print(\"\")\n",
    "\n",
    "# Verify that all domains have the same asins - check intersection of asins\n",
    "og_set = set(domains[list(domains.keys())[0]][\"json_files\"].keys())\n",
    "\n",
    "for domain_id, domain in domains.items():\n",
    "\tif set(domain[\"json_files\"].keys()) != og_set:\n",
    "\t\tprint(f\"Domain {domains_map[domain_id]} has different asins than the first domain\")\n",
    "\telse:\n",
    "\t\tprint(f\"Domain amazon.{domains_map[domain_id]} has the same asins as the first domain - OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files(files: list) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a dictionary with different objects for analyzing the categories of products quickly\n",
    "\t'''\n",
    "\t# category_id: int, product_id: str (ASIN)\n",
    "\tcategory_map = {} # category_id -> category_name # ; all categories\n",
    "\tcategory_tree = {} # category_id -> { subcategory_id -> ... } ; # tree of all categories\n",
    "\tcategory_products = {} # category_id -> { product_id -> True } ; # from product[\"categories\"]\n",
    "\tcategory_products_leafs = {} # category_id -> { product_id -> True } ; # only leaf categories (last element in category_tree)\n",
    "\tproducts_categories = {} # product_id -> {category_id -> True} # uses root categories\n",
    "\tproducts = {} # product_id -> { product_data } # shrunk down product object data\n",
    "\tproduct_types = {} # type_id (string) -> { product_id -> True } # from product[\"type\"]\n",
    "\n",
    "\tfailed_files = []\n",
    "\tfor i, file in enumerate(files):\n",
    "\t\tprint(f\"Processing file {i+1}/{len(files)} ({file})\\r\", end=\"\")\n",
    "\t\ttry:\n",
    "\t\t\tdata = {}\n",
    "\t\t\twith open(file, \"r\") as f:\n",
    "\t\t\t\tdata = json.load(f)\n",
    "\t\t\tproduct = data[\"products\"][0] # we assume there is only one product per file as we query the API by ASIN\n",
    "\t\t\tasin = product[\"asin\"]\n",
    "\t\t\tproduct_root_category = product[\"rootCategory\"]\n",
    "\t\t\tproduct_categories = product[\"categories\"]\n",
    "\t\t\tproduct_category_tree = product[\"categoryTree\"]\n",
    "\t\t\tleaf_category = product_category_tree[-1][\"catId\"]\n",
    "\t\t\tproduct_type = product[\"type\"]\n",
    "\t\t\tproducts[asin] = {\n",
    "\t\t\t\t\"file\": file,\n",
    "\t\t\t\t\"asin\": asin,\n",
    "\t\t\t\t\"title\": product[\"title\"],\n",
    "\t\t\t\t\"type\": product_type,\n",
    "\t\t\t\t\"root_category\": product_root_category,\n",
    "\t\t\t\t\"leaf_category\": leaf_category,\n",
    "\t\t\t\t\"categories\": product_categories,\n",
    "\t\t\t\t\"category_tree\": product_category_tree,\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t# Process product types\n",
    "\t\t\tif product_type not in product_types:\n",
    "\t\t\t\tproduct_types[product_type] = {}\n",
    "\t\t\tproduct_types[product_type][asin] = True\n",
    "\n",
    "\t\t\t# Use leaf category to fill category_products_leafs\n",
    "\t\t\t# These are the actual specific categories that we want to use for filtering\n",
    "\t\t\tif leaf_category not in category_products_leafs:\n",
    "\t\t\t\tcategory_products_leafs[leaf_category] = {}\n",
    "\t\t\tcategory_products_leafs[leaf_category][asin] = asin\n",
    "\n",
    "\t\t\t\n",
    "\t\t\t# Process rootCategory first\n",
    "\t\t\tif product_root_category not in category_map:\n",
    "\t\t\t\tcategory_map[product_root_category] = product_root_category # if we don't know the name, we use the id still\n",
    "\t\t\t\n",
    "\t\t\t# Process categories\n",
    "\t\t\tfor category in product_categories:\n",
    "\t\t\t\tif category not in category_map:\n",
    "\t\t\t\t\tcategory_map[category] = category # if we don't know the name, we use the id still\n",
    "\t\t\t\tif category not in category_products:\n",
    "\t\t\t\t\tcategory_products[category] = {}\n",
    "\t\t\t\tcategory_products[category][asin] = products[asin]\n",
    "\t\t\t\tif category not in products_categories:\n",
    "\t\t\t\t\tproducts_categories[asin] = {}\n",
    "\t\t\t\tproducts_categories[asin][category] = True\n",
    "\t\t\t\n",
    "\t\t\t# Fill category tree\n",
    "\t\t\t# the final category seems to coincide with the first element in \"categories\" - should we only use this\n",
    "\t\t\t# to match products so that a single product can only be in one \"main\" category?\n",
    "\t\t\tcurrent_tree_level = category_tree # set it to the root\n",
    "\t\t\tfor category_tree_object in product_category_tree:\n",
    "\t\t\t\tcategory_id = category_tree_object[\"catId\"]\n",
    "\t\t\t\tcategory_name = category_tree_object[\"name\"]\n",
    "\t\t\t\t# set name if not set yet or if its value is the id\n",
    "\t\t\t\tif category_id not in category_map or category_map[category_id] == category_id:\n",
    "\t\t\t\t\tcategory_map[category_id] = category_name\n",
    "\t\t\t\t# add it to the tree if not set yet\n",
    "\t\t\t\tif category_id not in current_tree_level:\n",
    "\t\t\t\t\tcurrent_tree_level[category_id] = {}\n",
    "\t\t\t\t# go one level deeper\n",
    "\t\t\t\tcurrent_tree_level = current_tree_level[category_id]\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tfailed_files.append((file, e))\n",
    "\treturn_object = {\n",
    "\t\t\"category_map\": category_map,\n",
    "\t\t\"category_tree\": category_tree,\n",
    "\t\t\"category_products\": category_products,\n",
    "\t\t\"category_products_leafs\": category_products_leafs,\n",
    "\t\t\"products_category\": products_categories,\n",
    "\t\t\"product_types\": product_types,\n",
    "\t\t\"failed_files\": failed_files,\n",
    "\t\t\"products\": products\n",
    "\t}\n",
    "\tprint(\"\") # to clean up the line\n",
    "\treturn return_object\n",
    "\n",
    "domains_parsed = {}\n",
    "\n",
    "for i, domain_id in enumerate(domains):\n",
    "\tprint(f\"Parsing domain {i+1}/{len(domains)}: amazon.{domains_map[domain_id]}\")\n",
    "\ttime_start = time.time()\n",
    "\tdomains_parsed[domain_id] = parse_files(list(domains[domain_id][\"json_files\"].values()))\n",
    "\ttime_end = time.time()\n",
    "\tprint(f\"Domain amazon.{domains_map[domain_id]} parsed in {time_end - time_start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of failed files for each domain\n",
    "for domain_id, domain in domains_parsed.items():\n",
    "\tprint(f\"Domain amazon.{domains_map[domain_id]} got {len(domain['failed_files'])} failed files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the domain with the fewest failed files for category analysis\n",
    "domain_id = min(domains_parsed, key=lambda x: len(domains_parsed[x][\"failed_files\"]))\n",
    "print(f\"Selected domain amazon.{domains_map[domain_id]} for category analysis\")\n",
    "\n",
    "parsed_data = domains_parsed[domain_id]\n",
    "\n",
    "# NOTE: Failed files in domains_parsed could still contain valid CSV data but have some missing fields\n",
    "#       which may not be essential for category analysis and index creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive count using the category_tree object\n",
    "# using depth first search\n",
    "def count_products_in_category(parsed_data: dict, category_id: int, current_node: dict = None) -> int:\n",
    "\t'''\n",
    "\t\tReturns the number of products in the given category (including subcategories) using the category_tree object\n",
    "\t\tfrom the parsed_data object.\n",
    "\t\tThe category_id can be any part of the tree.\n",
    "\t'''\n",
    "\t# 1. find the node with the given category_id\n",
    "\t# 2. count the number of products for all subcategories\n",
    "\t# 3. return the sum of the counts\n",
    "\t# 4. if no subcategories, return the number of products for the given category\n",
    "\t# 5. if category_id is not in the tree, return -1\n",
    "\t# NOTE: category_id can be any part of the tree\n",
    "\tif current_node is None:\n",
    "\t\tcurrent_node = parsed_data[\"category_tree\"]\n",
    "\tif category_id in current_node: # we found the node from which we start counting\n",
    "\t\ttotal_count = 0\n",
    "\t\tif category_id in parsed_data[\"category_products\"]: # if not we assume it's a root category and we don't count it\n",
    "\t\t\ttotal_count += len(parsed_data[\"category_products\"][category_id])\n",
    "\t\tfor subcategory_id in current_node[category_id]:\n",
    "\t\t\ttotal_count += count_products_in_category(parsed_data, subcategory_id, current_node[category_id])\n",
    "\t\treturn total_count\n",
    "\tfor subcategory_id in current_node:\n",
    "\t\tcount = count_products_in_category(parsed_data, category_id, current_node[subcategory_id])\n",
    "\t\tif count != -1:\n",
    "\t\t\treturn count\n",
    "\treturn -1\n",
    "\n",
    "\n",
    "def print_basic_statistics(parsed_data: dict):\n",
    "\tprint(f\"Number of categories: {len(parsed_data['category_map'])}\")\n",
    "\tprint(f\"Number of products: {len(parsed_data['products_category'])}\")\n",
    "\tprint(f\"Number of root categories: {len(parsed_data['category_tree'])}\")\n",
    "\t# print root categories in human readable format\n",
    "\tfor root_category_id in parsed_data[\"category_tree\"]:\n",
    "\t\t# print(f\" - {parsed_data['category_map'][root_category_id]}: {len(parsed_data['category_products'][root_category_id])}     (catId={root_category_id})\")\n",
    "\t\t# we need a different way to print the product counts as we exclude root categories that are not in \"categories\" for any products\n",
    "\t\t# da a recursive count\n",
    "\t\tcount = count_products_in_category(parsed_data, root_category_id)\n",
    "\t\tprint(f\" - {parsed_data['category_map'][root_category_id]}: {count}    (catId={root_category_id})\")\n",
    "\tprint(\"\")\n",
    "\tprint(f\"Number of failed files: {len(parsed_data['failed_files'])}\")\n",
    "\t# if len(parsed_data[\"failed_files\"]) > 0:\n",
    "\t# \tfor failed_file in parsed_data[\"failed_files\"]:\n",
    "\t# \t\tprint(f\" - '{failed_file[0]}' failed because:  '{failed_file[1]}'\")\n",
    "\n",
    "print_basic_statistics(parsed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_category_tree(parsed_data: dict, level: int = 0):\n",
    "\t'''\n",
    "\t\tPrints category tree in a readable format (substitutes category ids with category names)\n",
    "\t'''\n",
    "\tfor category_id, subcategories in parsed_data[\"category_tree\"].items():\n",
    "\t\t# indent_char = \"\\t\"\n",
    "\t\tindent_chat = \"    \"\n",
    "\t\tindent = indent_chat * level\n",
    "\t\tprint(indent + parsed_data[\"category_map\"][category_id])\n",
    "\t\tprint_category_tree({\"category_tree\": subcategories, \"category_map\": parsed_data[\"category_map\"]}, level+1)\n",
    "\n",
    "# Best inspected in a text editor (tab sizes here are 8, so it looks weird in Jupyter notebook cell output)\n",
    "# print_category_tree(parsed_data)\n",
    "# should just use the bottom function to print the tree as json with substitute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_category_ids(parsed_data: dict) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a category tree with human readable category names instead of category ids\n",
    "\t'''\n",
    "\tcategory_map = parsed_data[\"category_map\"]\n",
    "\tcategory_tree = parsed_data[\"category_tree\"]\n",
    "\tcategory_tree_substituted = {}\n",
    "\tfor category_id, subcategories in category_tree.items():\n",
    "\t\tcategory_tree_substituted[category_map[category_id]] = substitute_category_ids({\"category_map\": category_map, \"category_tree\": subcategories})\n",
    "\treturn category_tree_substituted\n",
    "\n",
    "\n",
    "# Basic JSON print of the category tree\n",
    "print(json.dumps(substitute_category_ids(parsed_data), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of products for each category sorted by number of products\n",
    "for category_id, products in sorted(parsed_data[\"category_products\"].items(), key=lambda x: len(x[1]), reverse=True):\n",
    "\tprint(f\"{parsed_data['category_map'][category_id]}: {len(products)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of products for each root category\n",
    "def get_root_category_products_count(parsed_data: dict) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a dictionary with root category ids as keys and number of products as values\n",
    "\t'''\n",
    "\troot_category_products_count = {}\n",
    "\tfor asin, product in parsed_data[\"products\"].items():\n",
    "\t\troot_category_id = product[\"root_category\"]\n",
    "\t\tif root_category_id not in root_category_products_count:\n",
    "\t\t\troot_category_products_count[root_category_id] = 0\n",
    "\t\troot_category_products_count[root_category_id] += 1\n",
    "\treturn root_category_products_count\n",
    "\n",
    "root_category_products_count = get_root_category_products_count(parsed_data)\n",
    "root_category_products_count = {parsed_data[\"category_map\"][k]: v for k, v in root_category_products_count.items()}\n",
    "print(f\"{json.dumps(root_category_products_count, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_category_files(parsed_data: dict, root_category_id: int) -> list:\n",
    "\t'''\n",
    "\tReturns a list of file paths of products in the given root category\n",
    "\t'''\n",
    "\tfiles = []\n",
    "\tfor asin, product in parsed_data[\"products\"].items():\n",
    "\t\tif product[\"root_category\"] == root_category_id:\n",
    "\t\t\tfiles.append(product[\"file\"])\n",
    "\treturn files\n",
    "\n",
    "# Select only \"Electronics\" root category\n",
    "electronics_root_category_id = 172282\n",
    "electronics_files = get_root_category_files(parsed_data, electronics_root_category_id)\n",
    "print(f\"Electronics root category has {len(electronics_files)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of root categories for electronics\n",
    "electronics_parsed_data = parse_files(electronics_files)\n",
    "print_basic_statistics(electronics_parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(substitute_category_ids(parsed_data), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_product_types_count(product_types: dict):\n",
    "\t'''\n",
    "\t\tPrints the number of products per type\n",
    "\t'''\n",
    "\tprint(\"Product types:\")\n",
    "\tcounts = {}\n",
    "\tfor product_type in product_types:\n",
    "\t\t# print(f\"{product_type}: {len(product_types[product_type])}\")\n",
    "\t\tcounts[product_type] = len(product_types[product_type])\n",
    "\tcounts = {k: v for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\tfor product_type in counts:\n",
    "\t\tprint(f\"{product_type}: {counts[product_type]}\")\n",
    "\t\n",
    "print_product_types_count(parsed_data[\"product_types\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* we could pretty much rely almost entirely on product types and then further split by product leaf category for certain product types - for example COMPUTER_DRIVE_OR_STORAGE could be split by product leaf category to get separate insights for HDD, SSD, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_types_count(product_types: dict, minimum_count: int) -> dict:\n",
    "\t'''\n",
    "\tReturns a dictionary with product types as keys and number of products as values\n",
    "\t'''\n",
    "\tcounts = {}\n",
    "\tfor product_type in product_types:\n",
    "\t\tcounts[product_type] = len(product_types[product_type])\n",
    "\tcounts = {k: v for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\tcounts = {k: v for k, v in counts.items() if v >= minimum_count}\n",
    "\treturn counts\n",
    "\n",
    "product_types_count = get_product_types_count(parsed_data[\"product_types\"], 100) # put 0 to get all types\n",
    "print(f\"{json.dumps(product_types_count, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out product types\n",
    "product_types_filter = [\n",
    "\tNone,\n",
    "\t\"KEYBOARD_MOUSE_SET\",\n",
    "]\n",
    "\n",
    "for product_type in product_types_filter:\n",
    "\tif product_type in product_types_count:\n",
    "\t\tdel product_types_count[product_type]\n",
    "\n",
    "# print(f\"{json.dumps(product_types_count, indent=2)}\")\n",
    "\n",
    "acccepted_product_types = list(product_types_count.keys())\n",
    "print(f\"Accepted product types: {json.dumps(acccepted_product_types, indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the products with type \"COMPUTER_DRIVE_OR_STORAGE\" into categories using the leaf category\n",
    "def split_products_by_leaf_category(product_type: dict, products: dict) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a dictionary with leaf category ids as keys and a dictionary of product ASINs as values\n",
    "\t'''\n",
    "\tleaf_category_products = {}\n",
    "\tfor asin in product_type:\n",
    "\t\tleaf_category = products[asin][\"leaf_category\"]\n",
    "\t\tif leaf_category not in leaf_category_products:\n",
    "\t\t\tleaf_category_products[leaf_category] = {}\n",
    "\t\tleaf_category_products[leaf_category][asin] = True\n",
    "\treturn leaf_category_products\n",
    "\n",
    "def print_leaf_category_products(leaf_category_products: dict, products: dict, category_map: dict, leaf_category_name: str, product_types_count: int):\n",
    "\t'''\n",
    "\t\tPrints the leaf category product counts for a given product type\n",
    "\t'''\n",
    "\tprint(f\"Leaf categories and their product counts for product type '{leaf_category_name}' ({len(leaf_category_products)} categories, {product_types_count} products total):\")\n",
    "\tfor leaf_category in leaf_category_products:\n",
    "\t\tprint(f\"{category_map[leaf_category]} (catId={leaf_category}) has {len(leaf_category_products[leaf_category])} products\")\n",
    "\t\t# for asin in leaf_category_products[leaf_category]:\n",
    "\t\t# \tprint(f\" - {products[asin]['title']}\")\n",
    "\n",
    "computer_drive_or_storage_categories = split_products_by_leaf_category(parsed_data[\"product_types\"][\"COMPUTER_DRIVE_OR_STORAGE\"], parsed_data[\"products\"])\n",
    "print_leaf_category_products(computer_drive_or_storage_categories, parsed_data[\"products\"], parsed_data[\"category_map\"], \"COMPUTER_DRIVE_OR_STORAGE\", len(parsed_data[\"product_types\"][\"COMPUTER_DRIVE_OR_STORAGE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What exactly is \"Internal Components\" (catId=17923671011) which has 1148 products?\n",
    "for i, asin in enumerate(computer_drive_or_storage_categories[17923671011]):\n",
    "\t# if i >= 10:\n",
    "\t# \tprint(\"...\")\n",
    "\t# \tbreak\n",
    "\tproduct = parsed_data['products'][asin]\n",
    "\tprint(f\"{asin}: {product['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = parsed_data[\"products\"][\"B0978VB5TF\"]\n",
    "print(hmm[\"title\"])\n",
    "print(hmm[\"file\"])\n",
    "print(parsed_data[\"category_map\"][hmm[\"leaf_category\"]])\n",
    "print(\"\")\n",
    "for category in hmm[\"categories\"]:\n",
    "\tprint(parsed_data[\"category_map\"][category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like we can still maybe separate \"Internal Components\" into \"Internal Solid State Drives\" and \"Internal Hard Drives\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try getting categories for all products in the \"Internal Components\" category for the \"COMPUTER_DRIVE_OR_STORAGE\" type\n",
    "# and see if we can separate them into \"Internal Solid State Drives\" and \"Internal Hard Drives\" or something else\n",
    "\n",
    "def get_category_counts_for_17923671011(computer_drive_or_storage_categories: dict, parsed_data: dict):\n",
    "\t'''\n",
    "\t\tReturns a dictionary with category ids as keys and a dictionary of product ASINs as values\n",
    "\t'''\n",
    "\tcategory_counts = {}\n",
    "\tfor asin in computer_drive_or_storage_categories[17923671011]:\n",
    "\t\tproduct = parsed_data[\"products\"][asin]\n",
    "\t\tfor category in product[\"categories\"]:\n",
    "\t\t\tif category not in category_counts:\n",
    "\t\t\t\tcategory_counts[category] = {}\n",
    "\t\t\tcategory_counts[category][asin] = True\n",
    "\treturn category_counts\n",
    "\n",
    "category_counts = get_category_counts_for_17923671011(computer_drive_or_storage_categories, parsed_data)\n",
    "for category in category_counts:\n",
    "\tprint(f\"{parsed_data['category_map'][category]} (catId={category}) has {len(category_counts[category])} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over again and return the dictionary with ASINs if product has cateogory 1292116011 (Internal Solid State Drives) or 1254762011 (Internal Hard Drives)\n",
    "\n",
    "def get_disk_categories_from_internal_components(computer_drive_or_storage_categories: dict, parsed_data: dict) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a dictionary with category ids as keys and a dictionary of product ASINs as values\n",
    "\t'''\n",
    "\tdisk_categories = {\n",
    "\t\t1254762011: {}, # Internal Hard Drives\n",
    "\t\t1292116011: {}, # Internal Solid State Drives\n",
    "\t}\n",
    "\tfor asin in computer_drive_or_storage_categories[17923671011]:\n",
    "\t\tproduct = parsed_data[\"products\"][asin]\n",
    "\t\tfor category in product[\"categories\"]:\n",
    "\t\t\tif category in disk_categories:\n",
    "\t\t\t\tdisk_categories[category][asin] = True\n",
    "\treturn disk_categories\n",
    "\t\n",
    "newly_split_internal_components = get_disk_categories_from_internal_components(computer_drive_or_storage_categories, parsed_data)\n",
    "for category in newly_split_internal_components:\n",
    "\tprint(f\"{parsed_data['category_map'][category]} (catId={category}) has {len(newly_split_internal_components[category])} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these back to the pool of categories for the \"COMPUTER_DRIVE_OR_STORAGE\" type using computer_drive_or_storage_categories\n",
    "# and remove the \"Internal Components\" category\n",
    "\n",
    "# computer_drive_or_storage_categories[1254762011] = newly_split_internal_components[1254762011]\n",
    "\n",
    "computer_drive_or_storage_categories_fixed = {}\n",
    "for category in computer_drive_or_storage_categories:\n",
    "\tif category != 17923671011:\n",
    "\t\tcomputer_drive_or_storage_categories_fixed[category] = computer_drive_or_storage_categories[category]\n",
    "for category in newly_split_internal_components:\n",
    "\tfor asin in newly_split_internal_components[category]:\n",
    "\t\tcomputer_drive_or_storage_categories_fixed[category][asin] = True\n",
    "\n",
    "# Print new counts\n",
    "print_leaf_category_products(computer_drive_or_storage_categories_fixed, parsed_data[\"products\"], parsed_data[\"category_map\"], \"COMPUTER_DRIVE_OR_STORAGE\", len(parsed_data[\"product_types\"][\"COMPUTER_DRIVE_OR_STORAGE\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* we have successfully split the data for internal components using internal SSD and HDD category ids - if we look up the counts, we have reduced the number of categories by 1 while the number of SSD and HDD increased by the number of those identified from internal components\n",
    "\n",
    "# TODO\n",
    "\n",
    "* edit the types for COMPUTER_DRIVE_OR_STORAGE in such a way that we remove that category and add specific subcategories:\n",
    "\t* Internal Solid State Drives (catId=1292116011) has 1659 products\n",
    "\t* Internal Hard Drives (catId=1254762011) has 1284 products\n",
    "\t* External Hard Drives (catId=595048) has 316 products\n",
    "\t* External Solid State Drives (catId=3015429011) has 126 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group products by type using the new split categories for \"COMPUTER_DRIVE_OR_STORAGE\"\n",
    "\n",
    "# remove COMPUTER_DRIVE_OR_STORAGE from accepted_product_types\n",
    "accepted_product_types = [x for x in accepted_product_types if x != \"COMPUTER_DRIVE_OR_STORAGE\"]\n",
    "\n",
    "# add the new categories to the start of the list\n",
    "to_add = [\n",
    "\t\"Internal Solid State Drives\",\n",
    "\t\"Internal Hard Drives\",\n",
    "\t\"External Hard Drives\",\n",
    "\t\"External Solid State Drives\",\n",
    "]\n",
    "for i in range(len(to_add)):\n",
    "\tto_add[i] = to_add[i].upper().replace(\" \", \"_\")\n",
    "\n",
    "print(json.dumps(to_add, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * Internal Solid State Drives (catId=1292116011) has 1659 products\n",
    "# * Internal Hard Drives (catId=1254762011) has 1284 products\n",
    "# * External Hard Drives (catId=595048) has 316 products\n",
    "# * External Solid State Drives (catId=3015429011) has 126 products\n",
    "accepted_product_types_added = to_add + accepted_product_types\n",
    "accepted_product_types_dict = {x: -1 for x in accepted_product_types_added}\n",
    "accepted_product_types_dict[\"INTERNAL_SOLID_STATE_DRIVES\"] = 1292116011\n",
    "accepted_product_types_dict[\"INTERNAL_HARD_DRIVES\"] = 1254762011\n",
    "accepted_product_types_dict[\"EXTERNAL_HARD_DRIVES\"] = 595048\n",
    "accepted_product_types_dict[\"EXTERNAL_SOLID_STATE_DRIVES\"] = 3015429011\n",
    "print(json.dumps(accepted_product_types_dict, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new dictionary with the new categories\n",
    "# keys are types or categories and values are modified dictionaries of products from parsed_data\n",
    "\n",
    "def get_products_for_categories(parsed_data: dict, storage_categories: dict, accepted_product_types: dict) -> dict:\n",
    "\t'''\n",
    "\t\tReturns a dictionary with category ids as keys and a dictionary of product ASINs as values\n",
    "\t'''\n",
    "\tproducts_for_categories = {}\n",
    "\tfor product_type, category_id in accepted_product_types.items():\n",
    "\t\tproducts_for_categories[product_type] = {}\n",
    "\t\tif category_id != -1: # if it's a split category for \"COMPUTER_DRIVE_OR_STORAGE\"\n",
    "\t\t\tfor asin in storage_categories[category_id]:\n",
    "\t\t\t\tproducts_for_categories[product_type][asin] = parsed_data[\"products\"][asin]\n",
    "\t\telse: # if it's a normal category from types\n",
    "\t\t\tfor asin in parsed_data[\"product_types\"][product_type]:\n",
    "\t\t\t\tproducts_for_categories[product_type][asin] = parsed_data[\"products\"][asin]\n",
    "\treturn products_for_categories\n",
    "\n",
    "products_for_categories = get_products_for_categories(parsed_data, computer_drive_or_storage_categories_fixed, accepted_product_types_dict)\n",
    "total_products = 0\n",
    "print(\"Products for constructed categories:\")\n",
    "for product_type in products_for_categories:\n",
    "\tprint(f\"{product_type}: {len(products_for_categories[product_type])}\")\n",
    "\ttotal_products += len(products_for_categories[product_type])\n",
    "print(\"\")\n",
    "print(f\"Total products: {total_products}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
